{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749564c4",
   "metadata": {},
   "source": [
    "## GAN의 평가(Evaluation)\n",
    "\n",
    "### 평가(Evaluation)\n",
    "\n",
    "이 강의에서는 GAN 평가에 대해 배웁니다. GAN이 갖기를 원하는 몇 가지 기준 또는 성질을 이해하는 것으로 시작합니다. 먼저 GAN을 평가하는 것이 왜 어려운지 알 수 있습니다. 그런 다음 가장 중요한 두 가지 속성인 **충실도**와 **다양성**에 대해 배웁니다. \n",
    "\n",
    "* GAN의 평가는 왜 어려운가?\n",
    "\n",
    "* 두 성질 : **충실도(fidelity)와 다양성(diversity)**\n",
    "\n",
    "### 왜 GAN의 평가는 어려운가?\n",
    "\n",
    "GAN을 평가하는 것은 일반적으로 특정 시점에서 신경망의 가중치가 고정된 모델 체크 포인트를 사용하며, 그 출력을 일부 측정 항목(metric)과 비교하고, 이러한 측정 항목은 독립적인 평가를 위해 자신이 아닌 여러 모델에서 사용할 수 있다는 점에서 다른 신경망 모델을 평가하는 것과 유사합니다. 그러나 GAN을 평가하는 것은 특별히 어려운 작업이지만, 최근 많은 진전을 보인 활발한 연구 분야이다.  \n",
    "<img src=\"./images/C2W1.01.png\" width=\"700\">\n",
    "\n",
    "설명을 위해서, 먼저 지도 학습을 통한 분류기를 고려해봅니다. 이미지들이 어떻게 분류되어야 할 지를 아는 레이블이 있는 테스트를 통하여 시험할 수 있습니다. 그리고 이러한 레이블을 기반으로 모델이 옳고 그른지 평가할 수 있습니다. 여기에서 정확함을 감지할 수 있습니다. 그리고 일반적으로 모델이 얼마나 옳고 그른지 평가할 수 있는 테스트 세트가 있습니다. 그리고 이 테스트 세트를 사용하여 여러분의 모델 또는 다른 사람들의 모델을 평가할 수 있습니다. \n",
    "그러나 GAN을 사용하면 임의의 노이즈를 전달하고 이 가짜 이미지를 얻게 됩니다. 그러나 이러한 생성된 이미지가 얼마나 사실적인지 알 수 있는 구체적인 방법은 없습니다. 당신은 그것이 생성해야 할 정확한 픽셀을 모릅니다. 즉, 여기 이 픽셀은 약간 빗겨나갔으며, 여기는 녹색으로 되어 있어야 할 곳인데, 라고 말할 수도 없습니다. \n",
    "그래서 이 때문에, 이 노이즈 벡터가 들어가서, **생성해야 할 픽셀에 대한 명확한 목표가 없습니다**. 따라서 이 모델은 걸작을 그리는 방법을 배우는 고급 예술가와 비슷합니다. 분명한 옳고 그름이 있기 때문에 분류기처럼 정확성을 알 수 있는, 알려진 그림에서 정확한 브러시 스트로크를 배우는 것과는 대조적입니다. \n",
    "추가적으로, 실제와 가짜를 구분하는 이 GAN의 **판별자는 완벽에 도달하지 않습니다**. 그리고 종종 특정 생성기에 대해 실제 이미지와 가짜 이미지를 구별하는 데 지나치게 과적합합니다. 따라서 실제 이미지와 가짜 이미지를 구분하는 것이 유용 할 수 있기 때문에 좋다 라고 생각할 수 있으나, 그렇지 않습니다. **특정 생성기의 많은 이미지에 적합될 것입니다**. 즉, 매우 실제적으로 보이지만 특정 특징을 포착하여 가짜로 판단할 수 있기 때문입니다. 그래서 그러한 특정 특징은 작을 것일 수도 있으며, 때로는 인지 가능한 정도의 것까지도 생성기가 만들 수 있습니다. 이로 인해 완벽하거나 보편적인 판별자는 없으며, 두 개의 생성기를 보면서 이것이 다른 것보다 낫다는 것을 확신할 수 없습니다.    \n",
    "\n",
    "<br>\n",
    "<img src=\"./images/C2W1.02.png\" width=\"700\">\n",
    "\n",
    "그렇다면 GAN을 어떻게 평가할 수 있을까요? 글쎄요, 당신은 먼저 원하는 이러한 속성의 원하는 기준을 정의하여 시작할 수 있습니다. 그리고 하나의 주된 기본 속성, 기본 목표는 확실히 **충실도** 또는 생성된 이미지의 품질과 이미지가 **얼마나 사실적으로 보이는가** 입니다. \n",
    "그리고 전체 품질과 전체 충실도를 사실적인 요소로 생각할 수도 있지만, 이미지의 선명도도 고려할 수 있습니다. 예를 들어 흐릿한 얼굴은 여전히 사실적으로 보일 수 있지만 말 그대로 충실도가 높지는 않습니다. 따라서 이 사람 사진의 충실도는 여기에서 꽤 좋습니다. \n",
    "그러나 단일 이미지만을 생성하는 것은 생성기에서 원하는 것이 아닙니다. 좋은 생성기는 또한 매우 다양한 이미지를 생성합니다. 여기서 이 하나의 이미지를 생성하는 것은 그다지 유용하지 않을 것입니다. 따라서 일반적으로 관심을 갖는 두 번째 속성은 **다양성**입니다. 이 생성기가 생성할 수 있는 범위는 무엇이며, 다양한 이미지는 무엇입니까? 훈련 데이터 세트 또는 원하는 클래스 모델링에 내재된 다양성을 생성할 수 있습니까? 즉, 이 경우의 모든 개 중에서 모든 유형의 개, 모든 품종의 개, 다른 장소에 있는 개, 다른 위치에 있는 개를 모델링할 수 있습니까? 아니면 여기 이 얼굴처럼 하나의 매우 사실적인 이미지를 생성할 것입니까? 그렇기 때문에 GAN을 평가할 때 분명히 매우 중요한 이미지 품질을 고려하는 충실도뿐만 아니라, 또한 이러한 생성할 수 있는 이미지의 범위를 고려하는 다양성 측면도 중요합니다. 그래서 이 모든 것이 꽤 어려울 수 있습니다. 왜냐하면 어떤 것이 충분한 다양성을 가지고 있는지 여부를 실제로 어떻게 평가하거나 정량화할 수 있냐는 질문 때문입니다. 예를 들어, 훈련 데이터 세트를 모두 외우고 싶지는 않을 것입니다. 요약하면, 우리는 충실도와 다양성이라는 두 가지 속성을 가지고 있으며 두 축에 있습니다. 그리고 때로는 그것들을 서로 상충하는 것으로 생각할 수 있습니다. 이제 각각에 대해 조금 더 깊이 파고들겠습니다.\n",
    "<img src=\"./images/C2W1.03.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "충실도를 위해 GAN에서 이미지가 **얼마나 사실적**으로 보이는지 고려할 수 있습니다. 따라서 각 가짜 샘플에 대해 가장 유사한 실제 샘플과 얼마나 다른지 이렇게 생각할 수 있습니다. 그리고, 더 일반적으로 생각하여, 더 나은 표현을 얻기 위해 100개의 진짜에서 100개의 가짜가 얼마나 멀리 떨어져 있습니까? 그리고 당신은 원히트 GAN을 원하지 않으며, 좋고 나쁜 고충실도 및 저충실도 샘플을 놓치고 싶지 않습니다. 그것들은 이 GAN을 다른 GAN과 구별할 수 있게 해주기 때문에 지속적으로 좋은 결과를 줄 수 있는 GAN이 필요합니다. 이 비교를 수행할 수 있는 몇 가지 방법이 있으며, 이 과정의 뒷부분에서 그 중 일부에 대해 배울 것입니다.\n",
    "<img src=\"./images/C2W1.04.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "다양성에서는 생성된 이미지가 전체 다양성, 즉 **실제 분포의 다양성을 포함**하기를 원합니다. GAN이 동일한 단일 이미지만 생성하며, 매우 현실적인 것이라면 성능이 좋은 모델이 아닙니다. 이것은 모드 축소가 있을 때 발생하는 것과 유사하다는 것을 기억할 수 있습니다. 따라서 다양한 스타일로 작성된 이러한 8과 같은 다양한 이미지를 생성할 수 있는 GAN이 필요합니다. 그리고 진짜 100개의 퍼짐에 대한 예를 들어 100의 퍼짐을 측정하고 감지할 수도 있습니다. \n",
    "\n",
    "따라서 GAN을 평가할 때 충실도와 다양성은 모두 중요한 기준입니다. 충실도와 다양성을 포착하면 생성기가 가짜 이미지를 얼마나 잘 생성하는지 꽤 좋은 개념을 얻을 수 있습니다. 그리고 이것은 당신의 가짜 이미지가 당신의 실제 이미지와 얼마나 가까운지를 살펴보는 것일 수도 있습니다.\n",
    "<img src=\"./images/C2W1.05.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "#### 요약\n",
    "요약하면, GAN 들 간에 공정한 비교를 가능하게 하는 근거를 제공할 글로벌 감별자가 없기 때문에 평가하기가 어렵습니다. GAN을 평가하려면 이미지의 충실도 또는 품질을 고려해야 합니다. GAN에서 나오는 이미지의 다양성 또는 상이성. 그리고 이러한 속성을 통해 기준을 고려하면 다음 비디오에서의 GAN을 평가할 수 있는 방법을 배울 수 있습니다.\n",
    "\n",
    "* 실제 근거(ground-truth)가 없음 = 평가 하는 것이 어렵다.\n",
    "* 충실도는 이미지 품질을 측정하고 다양성은 다양함을 측정합니다.\n",
    "* 평가 지표는 충실도와 다양성을 정량화하려고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ac8fe4",
   "metadata": {},
   "source": [
    "## 이미지 비교\n",
    "이 비디오에서는 서로 다른 이미지들을 비교하는 방법에 대해 배울 것입니다. 예를 들어 GAN을 평가하기 위해 실제 이미지와 가짜 이미지를 비교합니다. 충실도와 다양성에 대한 이미지를 비교하는 것은 어려울 수 있습니다. 정확히 무엇을 비교해야 합니까? 먼저 **픽셀 거리(pixel distance)**가 무엇인지 탐색합니다. 간단한 접근 방식이지만 충분하지 않습니다. 그런 다음 **특징 거리(feature distance)**를 사용하여 이미지를 비교하게 되며, 이는 비교에서 더 큰 신뢰성을 제공합니다.\n",
    "\n",
    "* 픽셀 거리\n",
    "* 특징 거리\n",
    "\n",
    "### 픽셀 거리\n",
    "이미지를 비교하는 **간단한 접근 방식은 픽셀 간의 차이를 확인**하는 것이며, 이를 픽셀 거리라고 합니다. 여기에서 실제 이미지와 가짜 이미지를 사용하여 픽셀 값을 뺄 수 있습니다. 한 이미지에서 다른 이미지와 0에서 255 사이의 값을 얻은 다음 절대 차이를 얻습니다. 각 픽셀을 다른 픽셀로 빼면 각각의 차이점을 얻을 수 있습니다. 그리고 아마도 당신은 그들의 차이를 모두 더할 수 있습니다. 여기에서 총 차이는 0입니다. 지금까지는 이 두 이미지가 동일하고 여기에서 0이 나오기 때문에 멋지게 보입니다. 그래서 그들은 동일하게 보이고 절대 차이가 0이므로 서로 거리가 없습니다. 완벽합니다. 그러나 **픽셀 거리는 실제로 그렇게 신뢰할 수 없습니다**.\n",
    "<img src=\"./images/C2W1.06.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "예를 들어 가짜 이미지에서 이미지가 왼쪽으로 한 픽셀 이동했다고 상상해보십시오. 이것은 이미지가 실제로 유사하더라도 원본 이미지 또는 여기의 실제 이미지에서 잠재적으로 큰 픽셀 거리를 가질 수 있습니다. 수백만 픽셀의 고해상도 이미지를 볼 때 눈에 감지할 수 없을 정도로 다릅니다. 따라서 이 이미지가 매우 크고 1픽셀만 이동했다면 아무 것도 눈치채지 못할 것입니다. 그러나 픽셀 거리를 기반으로 하면 이 절대적인 차이는 엄청날 것입니다. 그러면 여기 있는 이 모든 값은 모두 150으로 평가됩니다. 그리고 이 값을 모두 합치면 900이라는 엄청난 픽셀 거리를 얻게 됩니다.\n",
    "<img src=\"./images/C2W1.07.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "따라서 한 가지 대안은 **픽셀 대신 이미지의 더 높은 수준의 특징을 보는 것**입니다. 개는 두 개의 눈을 가지고 있습니까? 눈 밑의 코가 있읍니까? 털이 있습니까? 그리고 이 더 높은 수준의 의미 정보는 작은 픽셀 이동과 같은 변화에 덜 민감할 것입니다. 따라서 픽셀을 직접 보는 대신 두 눈, 축 늘어진 귀, 코와 같은 특징을 사용하여 이미지를 압축하거나 설명할 수 있습니다. 그런 다음 **추출된 이러한 특징을 사용하여 이미지를 비교할 수 있습니다**. 알겠죠? 이제 특징을 살펴보면서, 이 이미지들을 특징 수준이라고 부르는 비교를 해보겠습니다. 그리고 이것은 이미지 간의 더 높은 수준의 의미 정보를 비교하기 위한 좋은 트릭입니다. 그리고 GAN 이외의 것에서도 꽤 일반적입니다. 따라서 이러한 추출된 특징을 사용하면 **이미지의 작은 차이에 대한 평가가 덜 민감**합니다. 그리고 이 예에서 이미지의 **배경은 다르지만 둘 다 여전히 개로 식별**할 수 있습니다. 픽셀 거리를 사용하면 가짜 이미지가 실제와 정말 거리가 멉니다. 그리고 다음 비디오에서 이러한 특징을 얻는 방법과 특징 거리를 계산하는 방법에 대한 자세한 내용을 볼 수 있습니다. 여기서 흥미로운 점은 이 두 이미지가 어떤 면에서 비슷하다는 것을 알 수 있다는 것입니다. 둘 다 두 눈을 가지고 있습니다. 하지만 여기 이 녀석은 두 개의 축 늘어진 귀를 가지고 있고, 이 녀석은 한 개만 그린 것이고, 이 녀석은 다리가 다섯 개 있는 것 같습니다. 그래서 그것은 가짜 쪽에서 약간 벗어난 것처럼 보이고, 둘 다 코가 있습니다. 따라서 눈이 하나 또는 코가 두 개인 진짜에서 더 멀리 떨어져 있는 가짜 이미지를 상상할 수도 있습니다. 또는 다리가 없고 두 개의 축 늘어진 귀가 있는 진짜 이미지에 더 가까운 것일 수 있습니다. 그리고 이것이 이 이미지들 사이의 거리를 얻는 방법입니다. 이 특징 수준을 추가합니다.\n",
    "<img src=\"./images/C2W1.08.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "#### 요약\n",
    "요약하자면, 평가할 때 이미지를 픽셀 거리와 비교하는 것은 간단하지만 너무 민감하고 신뢰할 수 없습니다. 특징 거리는 픽셀 대신 더 높은 수준의 특징을 추출하여 이미지를 비교함으로써 말 그대로 그 대안입니다. 결과적으로 더 높은 수준의 정보를 보기 때문에 더 신뢰할 수 있습니다.\n",
    "\n",
    "* 픽셀 거리는 단순하지만 신뢰할 수는 없다.\n",
    "* 특징 거리는 이미지의 좀 더 높은 의미의 특징을 사용하며, 좀 더 신뢰할수 있게 해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2e8e5b",
   "metadata": {},
   "source": [
    "## 특징 추출\n",
    "\n",
    "이 비디오에서는 이미지에서 **특징을 추출하는 방법**을 배우게 되며 이러한 특징은 이미지 간의 특징 거리를 계산할 때 사용할 것입니다. 구체적으로, 분류기로서는 **일반적인 자연 이미지를 모델링할 수 있는 것으로 간주될 정도로 많은 이미지와 사진에 대해 훈련된 분류기를 사용하여 특징을 추출하는 방법**을 배웁니다. 이 많은 이미지는 일반적으로 **ImageNet**이라는 유명한 데이터 세트에서 가져온 것입니다. 이 비디오에서도 다룰 것입니다.\n",
    "\n",
    "* 사전 훈련된 분류기를 사용한 특징 추출\n",
    "* ImageNet 자료\n",
    "\n",
    "따라서 실제 이미지와 가짜 이미지 간의 **특징 거리**를 계산하려면 먼저 해당 이미지에서 **특징을 추출**하는 방법이 필요합니다. \n",
    "일반적으로 많은 이미지와 이상적으로는 **추출하려는 특징과 다소 관련이 있는 클래스의 데이터에서 사전 훈련된 분류기의 가중치를 사용**하여 특징 추출기를 얻을 수 있습니다. \n",
    "예를 들어 분류기가 개와 고양이를 분류하는 경우, 개와 고양이에는 꽤 좋은 특징 추출기가 될 것이지만 사무용 개체에는 적합하지 않을 수 있습니다. 이러한 사전 훈련된 모델의 가중치에는 분류하기 위해 필요한 많은 특징이 본질적으로 인코딩되어 있습니다. 예를 들어 식물에서 개의 분류에서는 이 젖은 코와 황금빛 코트와 눈이 무엇인지, 식물 모양이 어떻게 생겼는지 파악해야 하고, 이것이 여기의 맨 마지막 레이어에 없을 수도 있고, 다운스트림에 더 많은 노드가 있는 중간 레이어일 수 있으며, 도중에 이러한 특징 중 일부를 파악해야 합니다. **실제로 추출된 이러한 특징은 좀 더 추상적**이며, 젖은 코나 황금색 코트 또는 식물 모양에 대한 우리의 개념과 반드시 일치하지는 않습니다. GAN을 평가할 때마다 분류기를 구축하고 훈련해야 하는지 궁금할 것입니다. 고맙게도 수백만 개의 이미지와 수백 또는 수천 개의 클래스에 대해 **사전 훈련된 신경망**이 있으므로 대답은 \"아니오\"입니다. 이미지 입력에서 특징을 추출하는 데 연결해서 사용할 수 있으며, 이러한 이미지는 일반적으로 대부분의 자연스러운 이미지에 적용할 수 있을 만큼 충분히 넓은 것으로 간주됩니다. 즉, 실제 세계의 사진들입니다. 이러한 사전 훈련된 분류기는 공개적으로 쉽게 사용할 수 있으며, 훈련하고자 하는 다양한 GAN에서 사용할 수 있는 방법을 제공합니다. 따라서 이러한 분류기는 다양한 클래스를 분류할 수 있으며 결과적으로 네트워크에서 많은 관련 특징을 인코딩합니다.\n",
    "<img src=\"./images/C2W1.09.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "\n",
    "이러한 **사전-훈련된 분류기**를 사용하기 위해서는, 이 최종 출력의 분류 층을 임무를 원하지 않으며, 실제 분류 부분에 대하여 관심이 없습니다. 하지만 네트워크의 나머지는 가치가 있습니다. 가중치들은 최종적으로 분류 임무를 도울 중요한 특징들을 학습했습니다. 따라서, **최종 분류층을 지워버리고**, 당신이 집어넣은 이미지에 대한 유용한 정보를 담고 있는 이전 층의 출력을 가져옵니다. 여기에서 전형적인 컨볼루션 신경망의 최종 레이어 또는 컨볼루션, 풀링 및 완전 연결층들을 볼 수 있습니다. 일반적으로 출력층을 포함한 이 마지막 완전 연결 레이어를 제거할 수 있습니다. \n",
    "<img src=\"./images/C2W1.10.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "출력 특징을 얻는 가장 일반적인 장소는 분류에 사용되는 **마지막 완전 연결 층 이전의 풀링 층**이기 때문입니다. 이 풀링 층에서 가장 미세한 특징 정보를 가지고 있기 때문입니다. 즉, 이 층은 상당한 양의 정보를 인코딩하므로 해당 정보를 하나만 더 있는 이 완전 연결 층에 전달하여 이미지를 분류할 수 있습니다. 따라서 이 마지막 부분을 지워서 네트워크에서 자르고 이 마지막 풀링 레이어를 사용할 수 있습니다. 그리고 이것은 이 레이어에서 나오는 값을 의미합니다. 이는 본질적으로 여기의 중간 값을 취하는 것입니다. 500 x 500 입력에서 100개의 값이 나왔다고 가정해 보겠습니다. 여기 있는 100개의 값은 이 특정 입력 이미지에 대해 이 모델에서 추출된 특징을 나타냅니다. 그리고 이 레이어는 해당 특징 값을 추출하기 때문에 특징 레이어로 생각할 수 있습니다. 또한 이 특징 레이어가 입력보다 훨씬 적은 값을 출력할 것임을 즉시 알 수 있으므로 입력의 픽셀 값을 이러한 100개의 특징으로 압축합니다. \n",
    "<img src=\"./images/C2W1.11.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "특징 레이어로 더 이전 레이어들을 사용하는 것도 괜찮습니다.하지만 마지막 레이어를 사용하는 것이 가장 많은 정보를 가지고 있기 때문에 관례입니다. 그러나 여기의 최종 분류를 위한 클래스와 같이 데이터 세트 및 작업에 과적합됐을 수도 있습니다. \n",
    "따라서 네트워크의 역방향으로 이전 컨볼루션 또는 풀링 레이어로 되돌아갈수록 초기 레이어가 더 원시적인 정보를 얻는 데 더 좋다는 것을 의미합니다.. \n",
    "그리고 그러한 초기 레이어의 경우, 한 극단에서 가장 초기 레이어로 이동하면 아마도 수직 에지 감지를 의미하고 입력에서 수직 에지 주변의 특징을 추출할 수 있을 것입니다. 그에 반해서 출력이 여기 어딘가에 고양이를 예측하는 경우 이미지에 고양이가 있는지 여부와 같이 특정 이미지 클래스에 적용되는 특징이 있는 마지막 풀링 레이어에 해당합니다. 따라서 특징 레이어라고 부르는 층을 선택하는 것은 실험할 수 있는 것이지만,\n",
    "**일반적으로 이 마지막 풀링 레이어부터 시작**하는 것이 좋습니다. \n",
    "왜냐하면 이 레이어는 광범위한 작업에 포함된 거대한 데이터 세트에 대해 훈련된 것이기 때문입니다.<img src=\"./images/C2W1.12.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "그리고 그 거대한 데이터 세트는 일반적으로 ImageNet이므로, 좋은 시작은 **일반적으로 ImageNet에서 사전 훈련된 분류기를 사용**하는 것입니다.\n",
    "<img src=\"./images/C2W1.13.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "ImageNet은 14,000,000개 이상의 이미지와 20,000개의 카테고리가 있는 데이터 세트이며, 여기에서 이러한 이미지의 카테고리 중 일부를 볼 수 있습니다. \n",
    "ImageNet은 여러 유형의 개체와 함께 다양한 유형의 개 품종, 고양이 품종 및 상상할 수 있는 거의 모든 다른 유형의 동물을 포함합니다. \n",
    "그리고 이 데이터 세트에서 기본적으로 학습된 분류기에서 의미 있게 인코딩할 수 있는 충분한 정보를 제공합니다. \n",
    "해당 분류기에서 추출한 특징은 때때로 **ImageNet 임베딩**이라고 알려져 있습니다. \n",
    "왜냐하면, ImageNet 데이터 세트에 대해 훈련된 네트워크의 가중치를 사용하여 더 작은 정보 벡터로 변환한 이미지의 해당 정보를 포함하고 압축하여 다음 해당 임베딩과정으로 안내를 하기 때문입니다. \n",
    "\n",
    "그리고 이러한 특징, 이러한 임베딩은 더 널리 알려진 **특징 공간 또는 임베딩 공간에 존재하는 벡터**일 뿐입니다. 그래서 여러분은 이와 같은 이미지를 상상할 수 있습니다. 그리고 출력 특징은 실제로 $[-3, 2, 5]$ 와 같은 벡터일 뿐입니다. 특징 공간의 벡터를 나타내는 다양한 값으로, 이는 특징을 나타내며, 이를 다시 임베딩이라고도 합니다.\n",
    "<img src=\"./images/C2W1.14.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "#### 요약\n",
    "요약하자면, 네트워크를 잘라서 해당 출력 레이어 이전 레이어의 가중치를 사용하여 사전 훈련된 분류기에서 특징 추출기를 얻는 방법을 보았습니다. 마지막 풀링 레이어를 사용하는 것이 가장 일반적이지만 이전 레이어를 사용하면 더 기초적인 특징을 추출할 수 있습니다. 수백만 개의 이미지가 있는 ImageNet과 같은 대규모 데이터 세트에 대해 훈련된 분류기를 사용하여 수직 가장자리 또는 자연스러운 패턴과 같은 것입니다. 이미지에 대한 정말 의미 있는 정보를 특징으로 인코딩할 수 있습니다. 그리고 다음 강의에서는 ImageNet 데이터를 사용하는 인기 있는 분류기와 GAN을 평가하는 데 사용할 수 있는 방법에 대해 배웁니다.\n",
    "\n",
    "* 분류기 네트워크를 일찍 멈춰서 특징 추출기로 사용될 수 있다.\n",
    "* **마지막 풀링 층**이 특징 추출에 가장 흔히 사용된다.\n",
    "* 큰 자료인 ImageNet 에 대하여 훈련된 분류기들을 사용하는 것이 최상의 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8019d2",
   "metadata": {},
   "source": [
    "## Inception-v3 와 임베딩\n",
    "\n",
    "이 비디오에서는 imageNet에서 훈련할 수 있는 복잡한 합성곱 신경망 분류기인 Inception-v3 네트워크에 대해 알아봅니다. 이 섹션은 Inception-v3 네트워크에서 특징 임베딩을 추출하고, 이러한 임베딩을 비교하는 방법에 대해 설명합니다. 이 비교는 GAN을 평가하는 데 사용할 수 있습니다.\n",
    "\n",
    "* Inception-v3 구조\n",
    "* 추출된 특징 임베딩들 비교\n",
    "<br>\n",
    "\n",
    "지난 비디오에서 분류기를 특징 추출기로 사용할 수 있다는 것을 배웠습니다. 특히 광범위한 imageNet 데이터 세트에서 훈련된 분류기를 사용했습니다. 사용하는 정확한 네트워크는 다를 수 있지만 가장 일반적으로 사용하는 네트워크 중 하나는 Inception-v3 (또는 짧게 Inception) 입니다. **Inception**은 **42개의 레이어**로 구성되어 있지만 놀랍도록 비용이 많이 들고 계산 효율성이 높으며 **분류 작업**은 물론 **특징 추출기로 특히 유용**하며 잘 수행했습니다.  그리고 이것을 실제 이미지와 생성된 이미지를 비교하기 위한 특징 추출기로 사용할 것이기 때문에 여기에 집중하겠습니다. \n",
    "이것은 Inception-v3 네트워크의 표현이며, 이 분류기 네트워크를 가져와서, **분류를 위한 최종 완전 연결 층을 잘라낸, 다음 마지막 풀링 층을 사용**할 수 있습니다. 그래서 분류는 여기 화면 밖에서 일어나고 있고, 그것은 이미 잘렸고 여기에서 출력으로 볼 수 있는 것은 8x8x2048 입니다. 이것은 실제 출력이 아니며 마지막 컨볼루션 레이어에서 얻은 것입니다. 그 다음에 이것을 8x8 필터를 사용하여 마지막 풀링 레이어에 넣으면 2048 크기의 임베딩, 벡터를 얻습니다. 놀라운 점은 이러한 **2048 값만 출력**으로 얻을 수 있다는 것입니다. 이미지의 픽셀을 2048개의 값으로 압축하여 해당 이미지의 두드러진 특징을 나타낼 수 있습니다. 그리고 2048이라고 계속 말하는 이유는 많은 이미지에 비해 값이 많지 않기 때문입니다. 웹에서 볼 수 있는 많은 이미지는 RGB 색상을 위한 3개의 채널이 있는 1024x1024 픽셀입니다. 모두 합치면 3백만 픽셀이 넘으므로 2048의 임베딩 크기는 1000배 이상 작습니다. 이는 **이미지를 설명하는 데 필요한 값이 1000배 더 적으므로 지금은 특징 거리를 수행하는 것이 픽셀 거리보다 훨씬 더 나은 것** 같습니다. 특징 추출기가 이미지에 대한 정보를 압축하는 것도 유용합니다. 이렇게 하면 **이미지당 더 적은 차원으로 작업**할 수 있고 많은 수의 이미지를 비교하는 데 걸리는 **시간이 크게 줄어들기 때문**입니다.\n",
    "<img src=\"./images/C2W1.15.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "따라서 imageNet에서 이미지를 분류하도록 훈련된 Inception-v3 네트워크를 사용하여 이제 이미지에서 특징을 추출하여 GAN을 평가할 수 있습니다. 그리고 다시, 이 귀여운 강아지에게서 두 개의 눈, 두 개의 처진 귀, 하나의 코와 같은 특징을 얻을 수 있습니다. 물론 **실제 특징은 이러한 설명보다 조금 더 추상적**입니다. 그리고 표기법으로 이 특징 추출 모델은 특징을 추출하기 위해 이미지 $X$에 함수 또는 $\\phi$라는 매핑 함수를 적용합니다. 여기 $X$는 진짜 또는 가짜 이미지일 수 있습니다. \n",
    "여기서 $\\phi$는 최종층인 완전 연결된 레이어가 지원진 Inception 네트워크입니다. \n",
    "당신의 이러한 특징을 얻고, 이는 2048 값의 벡터인 임베딩을 구성합니다. \n",
    "그리고 이러한 **추출된 특징을 종종 이미지의 임베딩**(embedding)이라고 한다는 것을 배웠습니다. 왜냐하면 그것들은 이 저차원 공간으로 압축되고, 이 저차원 공간에서의 배치는 서로 상대적인 것을 의미하기 때문입니다. 실제로 유사한 특징을 가진 임베딩이 서로 더 가까운 곳, 즉 유사한 값을 취합니다. 예를 들어, 다른 개가 들어오면 이 개, 아마도 다른 골든 리트리버와 상당히 유사하지만 다른 위치에 있을 수 있으나, 이러한 유사한 특징을 추출하면 특징 벡터가 훨씬 더 가깝습니다. 그래서 원래의 그것은 $[-5, 4]$ 를 가질 것이고, 다른 하나는 $[-6, 4]$를 가지고 있다고 상상해 봅시다. 그래서 이 두 가지는 상당히 유사한 벡터입니다. 이제 이러한 특징이 전혀 없는 \"의자 이미지\"가 들어왔다면 이 두 가지와 매우 멀리 떨어져 있는 세 번째 특징 벡터를 갖게 됩니다. 예를 들어 여기에서는 $[1000, .001]$입니다. 여기에서는 이러한 임베딩에 대한 2차원만 표시하고 있지만, Inception 에는 2048  이라는 것을 기억하십시오.\n",
    "<img src=\"./images/C2W1.16.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "따라서 GAN을 평가하기 위해 다음 단계는 이러한 임베딩, 추출된 특징을 진짜와 가짜 간에 비교하는 것입니다. 그리고 이미지를 충분히 표현할 수 있도록, 일반적으로 여러 개의 진짜와 여러 개의 가짜에 적용합니다. \n",
    "개에 대한 몇 가지 가짜 예가 있다고 가정합시다. 그들의 특징을 추출하여 임베딩으로 얻게될 때, 이와 같다고 합시다. 이는 임베딩 벡터 값의 그림 표현으로, 분홍색 코를 가진 밝은 색 개들을 나타냅니다. 한편, 실제 이미지의 특징 임베딩에도 밝은 색의 개가 있지만 검은 코가 더 많이 있으므로, 이러한 이미지를 특징으로 비교하는 것이 픽셀로 비교하는 것보다 훨씬 더 의미가 있습니다. 간단한 픽셀 거리로 픽셀의 약간의 이동이 실제로는 동일한 두 이미지를 완전히 다르게 보이게 하는 방법을 기억하십니까? 따라서 이 두 개의 상당히 유사한 이미지는 특징 거리로는 실제로 매우 가깝습니다. 둘 다 밝은 색의 개이고 둘 다 핑크색 코를 가지고 있기 때문입니다. \n",
    "그러나 픽셀 거리에서 그들은 정말 멀리 떨어져 있을 것입니다. 왜냐하면 이 픽셀 하나가 그 픽셀 하나와 매우 다르다는 것을 알기 때문입니다. 그래서 그들은 그 픽셀 거리에서 멀리 떨어져 있을 것입니다. \n",
    "따라서 특징 거리를 얻으려면 피처들에 대한 값을 서로 빼서 직접 비교할 수 있습니다. \n",
    "따라서 이 모든 이미지들에 대한 벡터가 있고, 모든 가짜 벡터의 평균과 모든 진짜의 평균을 취하여 뺄 수 있다고 가정해 보겠습니다. 그것은 한 가지 방법이며 픽셀 거리를 수행하는 방법과 유사합니다. 다양한 벡터 사이의 유클리드 또는 코사인 거리를 얻을 수 있습니다. 또한 진짜 집합과 가짜 집합이 일종의 분포라고 생각하고 이러한 분포가 얼마나 멀리 떨어져 있는지 확인할 수 있습니다. 그리고 다음 비디오에서는 진짜와 가짜 사이의 특징 거리를 계산하는 방법을 배우게 됩니다. 이는 일반적인 평가 방법이므로 계속 지켜봐 주시기 바랍니다.\n",
    "<img src=\"./images/C2W1.17.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "\n",
    "#### 요약\n",
    "이제 imageNet에서 사전 훈련된 분류기로서 Inception 에 대해 상당히 많이 알게 되었습니다. 또한 최종 완전 연결 층을 잘라내어 특징 추출기로 사용할 수도 있습니다. 그리고 마지막 풀링 레이어의 중간 출력이 다른 이미지를 비교하는 데 사용할 수 있는 입력 이미지에 대한 특징 임베딩을 구성할 수 있는 방법. 즉, 진짜 이미지와 가짜 이미지 사이에서, 그리고 이 특징 공간에서 그것들이 얼마나 다른 지에 대한 감을 얻었습니다.\n",
    "\n",
    "* 자주 사용되는 특징 추출기 : Inception-v3 분류기, ImageNet 에 사전 훈련된 것으로, 마지막 층이 잘린 것\n",
    "* 이 특징들은 임베딩이라고 불림\n",
    "* 특징 거리를 비교하기 위해 임베딩들을 비교한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007415ac",
   "metadata": {},
   "source": [
    "### Frechet Inception Distance (FID)\n",
    "\n",
    "이 섹션에서는 **진짜 이미지와 생성된 이미지 간의 특징 거리를 측정**하는 데 가장 널리 사용되는 측정치인 **FID(Frechet Inception Distance)**에 대해 알아봅니다. 그래서 먼저 Frechet 거리에 대해 배우고, Frechet Inception Distance(FID)로 실제 임베딩과 가짜 임베딩에 적용하여 얼마나 멀리 떨어져 있는지 확인합니다. 마지막으로 **FID의 몇 가지 제한 사항**에 대해 알아봅니다. 평가는 생성 모델 연구에서 매우 열린 영역입니다.\n",
    "\n",
    "* Frechet distance\n",
    "* 평가 방법 : Frechet Inception Distance (FID)\n",
    "* FID 의 한계\n",
    "<br>\n",
    "\n",
    "수학자 Maurice Frechet의 이름을 딴 **프레셰 거리**라는 이름은 **곡선 사이의 거리를 측정**하는 데 사용되는 **거리 메트릭**이며, **분포를 비교하는 데에도 확장**할 수 있습니다. **도그 워커의 예**는 개가 한 커브를 따라 이동하고 있고, 워커가 다른 커브에 있는 **프레셰 거리를 설명하는 데 사용되는 고전적인 예**입니다. 따라서 개의 길은 파란색으로 표시하고 워커의 것은 이 주황색으로 표시됩니다. 각자의 속도로 갈 수는 있지만 어느 쪽도 뒤로 갈 수는 없습니다. 그것을 염두에 두십시오. 따라서 **이러한 곡선 사이의 Frechet 거리**를 계산하려면 **곡선을 처음부터 끝까지 걷는 데 필요한 최소 끈 길이**를 파악해야 합니다. 즉, **산책하는 동안 더 느슨하게 하지 않고도 개에게 줄 수 있는 최소한의 목줄**입니다. 이것이 두 곡선 사이의 Frechet 거리 뒤에 있는 직관입니다.\n",
    "<img src=\"./images/C2W1.18.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "**분포 사이의 Frechet 거리를 계산할 수도 있습니다. 두 분포 사이의 Frechet 거리가 해석적으로 해결되는 분포가 많이 있습니다**. 예를 들어, **두 개의 1차원 정규 분포 사이의 Frechet 거리**를 계산하는 간단한 공식이 있습니다. 여기에서 $\\mu$로 표시되는 분포 평균과 $\\sigma$로 표시되는 표준 편차를 모두 살펴보겠습니다. 그래서 하나의 분포는 $X$이고 하나는 $Y$입니다. 따라서 $X$는 개 워커이고 $Y$는 개로 주어지는, $X$와 $Y$를 상상할 수 있습니다. 평균은 중심에 대한 감각을 제공하고 표준 편차는 분산에 대한 감각을 제공합니다. 표기법으로, **평균의 차이와 표준 편차의 차이를 취한 다음 이러한 각 차이를 제곱**하여 서로 더 멀리 떨어져 있는 값에 페널티를 줄 수 있고, 따라서 **L2-norm 식의 거리** 개념으로 페널티를 적용할 수 있습니다.\n",
    "<img src=\"./images/C2W1.19.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "따라서 이것을 염두에 두고 **다변량 정규 분포**에 대해 이야기하기 위해 잠시 우회해 보겠습니다. 다변량 정규 분포는 **정규 분포의 개념을 더 높은 차원으로 일반화**합니다. 이러한 추가 차원을 사용하면, 단일 평균과 단일 표준 편차로 매개변수화하여 훨씬 더 복잡한 분포를 모델링할 수 있습니다. 이것은 실제 데이터의 특징들은 단일 정규 분포로 잘 분포되지 않을 수 있기 때문에 중요합니다. 개를 위한 검은 코 또는 튀어나온 혀와 같은 특정 특징 주변의 모드, 다른 영역에 봉우리가 있을 수 있습니다. 다변량 분포는 그것을 나타내는 것입니다. 다변량 정규 분포에서 특히 좋은 속성이 있습니다. 그래서 자주 사용합니다. 지금까지 여러분이 본 분포는 단변량입니다. 즉, 1차원입니다. 따라서 **다변량 정규 분포를 시각화하는 가장 쉬운 방법은 각 차원에 대해 단변량 정규 분포를 사용하는 것입니다.** 여기와 여기. 이것들은 함께 이 다크 서클 모양을 구성합니다. 실제로 3차원에서 당신을 똑바로 가리키고 있습니다. 값이 어두울수록 고도가 높아집니다. 따라서 이 결과 분포는 각 측면이 서로에 따라 얼마나 달라지는지, 얼마나 서로 영향을 미치는지 보여줍니다. 여기에서 양측은 이 센터에 동등하게 기여하며 실제로 그렇게 하는 데 서로 영향을 미치지 않습니다. 그래서 여러분은 이 멋진 둥근 중심, 정규 분포 피크가 여러분에게 나옵니다.\n",
    "\n",
    "<img src=\"./images/C2W1.20-0.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "그러나 차원이 공변(co-vary)하도록 허용할 수 있으며, 이는 서로 영향을 미침을 의미합니다. 즉, 한 차원의 특정 값으로 인해 다른 차원의 값이 발생할 가능성이 높아집니다. 따라서 결과 분포는 이와 같이 더 한쪽으로 치우쳐 보일 수 있습니다. 여기의 법선은 서로 다르게 영향을 미치더라도 여전히 동일하게 보입니다.\n",
    "\n",
    "<img src=\"./images/C2W1.21.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "따라서 **이를 표현하기 위해 분산의 개념을 일반화하는 공분산 행렬을 사용**하려고 합니다. 이 행렬은 시그마 제곱으로 보았던 것입니다. 여기서 시그마 자체는 표준 편차이고 시그마 제곱은 분산입니다. 분산은 이 정규 분포의 퍼짐을 정량화한다는 것을 기억하십시오. 따라서 공분산은 두 차원 간의 분산을 측정하기 때문에 적절하게 명명되었습니다. 따라서 이 공분산 행렬의 대각선을 따라 차원 내의 분산를 볼 수 있습니다. 예를 들어, 차원 1은 여기, 차원 2는 저쪽에 있습니다. 이 값이 2인 경우 예를 들어, 훨씬 더 넓게 퍼졌을 것이기 때문에 훨씬 더 많은 퍼짐과 훨씬 더 낮은 피크를 가진 훨씬 더 넓은 원을 보게 될 것입니다.\n",
    "<img src=\"./images/C2W1.20.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "모든 셀의 0은 해당 차원 간의 분산이 없음을 나타냅니다. 따라서 모든 비대각선 요소에 0이 있는 이 공분산 행렬은 두 차원이 독립적임을 의미합니다. 이러한 대각성분 값이 다르면, 즉 2 또는 0.5이면 이 피크는 훨씬 더 높고 스프레드는 더 적지만, 이 두 차원은 여전히 독립적입니다. 기술적으로 여기에서는 이 분포의 분산을 완전히 설명하기 위해 독립적이라고 가정할 때 이러한 공분산 값이 필요하지 않습니다.\n",
    "<img src=\"./images/C2W1.22.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "그러나 0 이 아닌 비대각 요소가 있는 공분산 행렬은 두 차원 간의 공분산을 나타내고, 음수 값은 음의 상관 관계를 나타내며, 여기에서 이 상관 관계가 진행되는 방향으로 생각할 수 있습니다. 이것은 y가 -x인 대각선을 따르는 추세를 나타내고, 만약 양수 값을 가지면 y가 x인 대각선을 따르는 반대의 추세가 됩니다. 분산의 값이 0.5이면 중심 주위에 더 많은 분산이 집중됩니다. \n",
    "<img src=\"./images/C2W1.23.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "이제 다변량 정규 분포 뒤에 약간의 직관이 생겼으므로, 단변량 정규 분포에 대한 Frechet 거리 공식을 생각해 보겠습니다. 이 공식은 단일 차원 공간에 있었습니다. 따라서 평균 차이의 제곱과 표준 편차 차이의 제곱으로 얻을 수 있습니다. 실제로 이것을 다변량의 경우로 일반화할 수 있습니다. 이는 방금 보고 있던 두 개의 다변량 정규 분포를 비교하는 것을 의미하며 공분산 행렬, 여기에서 대문자 시그마를 사용하는 것입니다. 일반화할 수 있는 두 공식 사이에는 많은 유사점이 있습니다. 이제 이것이 처음에는 어려워 보일 수 있으므로 이를 분해해 보겠습니다.\n",
    "<img src=\"./images/C2W1.24.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "첫째, 두 공식 모두 평균 사이의 거리의 제곱을 포함합니다. 다변수는 더 이상 단일 값이 아니므로 벡터의 크기를 취합니다. 이것이 여기의 길이 norm 입니다. 따라서 단일 차원에서 실제로 여전히 이와 같이 쓸 수 있지만, 여기에서는 정확히 이 norm 값으로 평가됩니다.\n",
    "<img src=\"./images/C2W1.25.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "단변량의 경우 표준 편차 간의 차이의 제곱 대한 공식을 전개할 수도 있습니다. 따라서 여기에서 이 제곱을 확장하면 이 항을 얻을 수 있으며 결국 다변량 공식과 매우 유사한 결과를 볼 수 있습니다. \n",
    "<img src=\"./images/C2W1.26.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "여기서 Tr 은 대각선 요소의 합인 행렬의 trace 를 나타냅니다. 예를 들어 $[[2, -1],[ -1, 2]]$ 에서, 트레이스는 이러한 대각 요소만 보고 합을 취합니다. 이것의 트레이스은 4 가 될 것이고 시그마 $\\Sigma_X$의 대각선 요소의 합은 실제로 분산의 합, 즉 각 차원이 다른 차원이 아닌 자체와 공분산의 합이라는 점에 유의하십시오. 다른 차원의 차원 간의 공분산은 이것 들에 대한 트레이스로 사용될 때, 여기에서 실제로 고려되지 않습니다. 또한 단변량의 경우 모든 것이 제곱된 것처럼 보입니다. 여기에 이 제곱이 있고 이것은 이 제곱근에 대해 제곱됩니다. 왜냐하면 $\\sigma$는 실제로 표준 편차이고 $\\sigma^2$은 분산이지만, 여기 아래에 있는 이 큰 시그마 $\\Sigma$는 공분산이고 $\\sigma^2$의 일반화인 분산입니다. 따라서, 일치합니다. 마지막으로 더 명확하게 하기 위해 여기 아래에 있는 이 행렬 제곱근은 각 개별 요소가 아닌 행렬의 제곱근을 얻습니다. 이 다변량 정상 Frechet 인셉션 거리, 여기서 알아가야 하는 것은, 단변량 사례와 매우 유사하며 해당 분포의 중심인 평균과 분산과 공분산으로 주어지는 퍼짐의 차이점을 살펴봄으로써 단변량 사례의 일반화일 뿐입니다. \n",
    "<img src=\"./images/C2W1.27.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "이제 이것이 어떻게 유용합니까? 다변량 정규 분포는 실제 이미지 특징 임베딩에서 이미지 특징의 많은 모드를 대략적으로 모델링할 수 있습니다.\n",
    "실제 이미지들의 임베딩으로부터 다변량 정규 분포를 구성할 수 있으며, \n",
    "예를 들어 50,000개의 실제 임베딩 벡터를 기반으로 분포 상황을 알수 있게 해줍니다. \n",
    "다변량 분포에 맞추는 것은 이러한 모든 예에서 평균 및 공분산 행렬을 찾는 것을 의미하므로 이제 가짜에 대해 동일한 작업을 수행하여 특징 임베딩을 얻습니다. 여기에 다변량 정규 분포를 맞춘 다음 이제 두 개의 다변량 정규 분포를 비교할 수 있습니다. \n",
    "내가 $X$라고 부를 진짜, $Y$라고 부를 가짜, 그리고 이것은 여기 여기에 있는 것들에 해당합니다. 여기서 $\\mu_X$는 진짜 임베딩의 평균이고 $\\mu_Y$는 가짜 임베딩의 평균입니다. $\\Sigma_X$는 진짜 임베딩의 공분산 행렬이고 $\\Sigma_Y$는 가짜 임베딩의 공분산 행렬이며 여기서 다시 사용됩니다. 이제 진짜와 가짜 사이에서 먼저 해당 이미지에 임베딩을 적용하고 각각에 다변량 정규 분포를 맞춘 다음 FID 점수를 계산할 수 있습니다. 이를 Frechet Inception Distance 또는 FID라고 하며 현재 가장 널리 사용되는 GAN 평가 메트릭입니다. \n",
    "따라서, **FID는 진짜 자료의 다변량 정규 분포의 통계와 가짜 자료의 다변량 정규 분포의 통계를 보고, 평균과 공분산 행렬인 이러한 통계가 서로 얼마나 떨어져 있는지 계산합니다**. 이러한 통계가 서로 가까울수록 가짜 임베딩이 실제 임베딩을 더 가깝게 만듭니다. 이제 FID는 임베딩이 다변량 정규 분포를 취한다고 가정합니다. 그것이 항상 완벽하게 정확하기 때문이 아니라 주로 근사적이고 계산하기 쉽기 때문입니다.\n",
    "\n",
    "여기에서 모든 것이 계산되면 진짜 분포와 가짜 분포의 차이를 나타내는 숫자가 남게 됩니다. 가짜가 진짜에 가까우면, 즉 모델이 진짜에 가까운 가짜 출력을 생성한다는 의미이므로 이 차이는 더 낮아집니다. **값이 작을수록 진짜와 가짜의 특징이 서로 비슷하다는 의미이므로 FID가 낮을수록 좋습니다**. 다른 평가 메트릭이 더 높은 값에 더 유리하기 때문에 때때로 사람들을 넘어지게 할 수 있지만, FID의 경우 가짜와 진짜 사이의 거리가 멀기 때문에 낮을수록 좋습니다. 불행히도 FID 값에 대해 해석 가능한 범위가 없습니다. 값이 0과 1 사이이고 0.5가 절반 또는 가짜를 의미한다면 좋지 않을까요? FID는 그렇지 않습니다. 그러나 일반적으로 0에 가까울수록 좋습니다. 0에서 가짜는 많은 임베딩에서 계산된 통계를 기반으로 진짜와 구별할 수 없기 때문입니다. 이 계산의 규모를 이해하기 위해 일반적으로 특징 벡터 또는 시작 네트워크의 임베딩에 2048개의 차원이 있음을 기억하십시오. FID는 일반적으로 최소 50,000개의 진짜와 50,000개의 가짜와 같이 많은 수의 샘플에 대해 계산됩니다. 많은 수의 샘플을 사용하면 예를 들어 몇 개의 샘플을 비교할 때 가질 수 있는 노이즈와 선택 편향이 줄어듭니다.\n",
    "\n",
    "<img src=\"./images/C2W1.28.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "\n",
    "#### FID의 단점\n",
    "\n",
    "또한 ImageNet 사전 훈련된 Inception-v3 모델은 **항상 원하는 특징을 얻지 못하거나 생성기 작업에 항상 의미가 있는 것은 아닙니다.** 예를 들어 GAN이 MNIST에서 손으로 쓴 숫자를 생성하도록 훈련된 경우, ImageNet은 개와 사람, 솔직히 말해서 많은 개와 같은 자연 사진으로 구성되어 있기 때문에 inception-v3 모델은 의미 있는 특징을 감지하지 못할 수 있습니다.\n",
    "<img src=\"./images/C2W1.29.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "또한 이전에 언급했듯이 충분한 샘플 범위를 위해 샘플 크기가 커야 하고, 따라서 FID 점수가 편향됩니다. 즉, FID 점수는 사용하는 샘플 수에 따라 변경됩니다. GAN이 변경되지 않고 실제 샘플도 변경되지 않기 때문에 그다지 좋지 않으므로 샘플 수가 점수에 영향을 미치지 않아야 합니다. 그러나 FID는 일반적으로 더 큰 표본 크기에서 더 낮습니다. 사용이 더 단순할수록 GAN이 더 나은 것처럼 보일 것입니다. 실제로는 더 좋지 않더라도 동일한 모델을 사용하여 비교하기 때문입니다. 이것은 메트릭에 있는 좋은 속성이 아니지만, 예를 들어 비편향 FID를 생성하는 등 이를 극복하기 위한 연구가 있지만 그 방법은 널리 사용되지 않습니다.\n",
    "\n",
    "<img src=\"./images/C2W1.30.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "또한 샘플 크기가 크면 FID 실행 속도가 느려집니다. \n",
    "마지막으로 이러한 분포에 대해 수집된 통계가 제한적이라는 것입니다. 분포의 처음 몇 성질에 해당하는 속성인 평균과 공분산만이라는 것입니다. 편향 및 첨도와 같이 친숙할 수 있는 분포의 다른 많은 성질도 있습니다. 평균과 공분산이 분포의 모든 측면을 포함하지 않으며, 분포도 정확히 다변량 정규가 아닐 가능성이 있음을 기억하십시오. 우리는 분포가 다변량 정규식이라고 가정하기 때문에 대체로 평균과 공분산을 얻습니다. 그러나 표본의 분포도 정확히 다변량 정규식이 아닐 가능성이 높지만 통계 및 비교 계산을 훨씬 더 쉽게 만들기 위해 그 가정을 하게 됩니다. 불행히도 이러한 단점은 원하는 모델을 찾고 모델을 디버그하기 위해 샘플을 정성적으로 살펴봐야 한다는 것을 의미합니다. 문제는 기존 평가 지표가 현재 진행 상황을 정확히 나타내는 가장 좋은 지표가 아니라는 것입니다. 그럼에도 불구하고 FID는 구현 및 사용이 쉽기 때문에 여전히 GAN을 평가하는 가장 인기 있는 방법 중 하나입니다. \n",
    "\n",
    "* 모든 특징을 잡아내지는 못한, 사전 훈련된 인셉션 모델을 사용함\n",
    "* 커다란 샘플 크기가 요구됨\n",
    "* 실행이 느림\n",
    "* 제한된 통계치를 사용한다: 평균과 공분산만 사용\n",
    "\n",
    "#### 요약\n",
    "\n",
    "요약하면 FID가 Frechet 거리를 사용하여 진짜 임베딩과 가짜 임베딩 간의 차이를 계산하는 방법을 배웠습니다. FID에는 몇 가지 단점이 있으므로 훈련 중에 저장된 모델 체크포인트 간의 FID 점수를 비교하여 어떤 것이 가장 좋은지 결정하는 대신 여전히 모델을 돌보며 샘플을 확인해야 합니다.\n",
    "\n",
    "* FID 는 진짜와 가짜 사이의 차이를 계산한다.\n",
    "* FID 는 Inception 모델과 다변량 정규 Frechet 거리를 사용한다.\n",
    "* FID 가잘 동작하려면 샘플의 크기가 커야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbe9709",
   "metadata": {},
   "source": [
    "### (Optional) Inception 점수 \n",
    "\n",
    "이 섹션에서는 Inception v3 모델을 사용하여 진짜와 가짜 사이의 거리를 계산하는 또 다른 방법에 대해 알아봅니다. 이 방법은 FID 이전에 개발되어 널리 사용되었지만 현재는 FID로 크게 대체되었고, 조건부 생성과 더 관련이 있습니다. 즉, 인셉션 점수라고 불리는 것은 많은 논문에서 보고되고 있으므로, 이것이 무엇을 측정하고 FID와 어떻게 다른지 아는 것이 좋습니다.\n",
    "\n",
    "* 또 다른 평가 측정치 : Inception Score (IS)\n",
    "* 직관, 기호, 단점\n",
    "<br>\n",
    "\n",
    "특징 추출에 사용된 ImageNet에서 사전 훈련된 Inception v3 분류기를 기억하십시오. **인셉션 점수도 이 모델을 사용**합니다. 그러나 FID와 달리 분류기를 특징 추출기로 사용하지 않습니다. **분류기를 그대로 유지**하고 이러한 중간 출력을 사용하지 않습니다. 먼저 생성된 이미지를 입력하고 inception v3 분류자가 분류한 이미지를 확인합니다. 예를 들어 이 이미지는 개 0.6, 고양이 0.3, 새 0.1처럼 보일 수 있습니다. 예를 들어, **한 클래스에서 직관적으로 높은 값**을 가진 개가 다른 클래스에서 낮은 값을 갖는 것은 이 이미지가 다른 클래스보다 분명히 한 클래스와 유사하다는 것을 암시합니다. 즉, 틀림없이 **높은 충실도**입니다. 물론 분류기 판단에 따라 많은 샘플에 대해 이 값을 관찰하여 이 GAN이 명확한 개체를 생성할 수 있는지 전반적으로 알 수 있습니다. 이 개가 0.9라면 더 잘할 것입니다. 그것은 틀림없이 훨씬 더 선명한 개를 가질 것입니다. 이제 GAN 이 다양한 출력을 생성하기를 원하기 때문에 많은 샘플을 살펴보고 많은 다른 클래스가 생성될 것으로 예상할 것입니다. 이 모든 클래스에서 훈련된 모든 샘플에서 개가 나타나고 고양이가 나타나고 새도 나타날 것이라고 예상할 수 있으며 매번 개가 아닙니다. 다시 말하지만, 이것은 이 분류기를 사용하여 이 분포가 무엇인지 확인함으로써 관찰할 수 있습니다. 모든 다른 클래스에 대한 이 다양성 확률 분포가 단일 클래스에서 뾰족하지 않고 멋지게 분산되기를 원할 것입니다.\n",
    "\n",
    "<img src=\"./images/C2W1.31.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "좀 더 공식적으로, 주어진 이미지의 클래스의 분포를 보는 첫 번째 측정은 이미지 x가 주어진 경우 클래스 y의 분포 p를 측정하는 것입니다. 명확하고 충실도가 높게 생성된 객체가 있는 이미지를 사용하면 해당 분포에 높은 확률을 가진 애완 동물이 있어야 합니다. 이는 몇 개의 선택적 클래스 또는 단일 클래스일 뿐이며, 여기서는 나머지 클래스에 대해 전반적으로 매우 낮은 확률을 가진 소수의 선택 클래스일 수 있습니다. \n",
    "이것이 근사하려는 것은 분류기에 의해 생성된 이미지에서 명확한 객체가 선택된다는 것입니다. 이것은 확률 분포가 해당 선택 지점에 클러스터링되어 있고 전체에 흩어져 있지 않기 때문에 낮은 엔트로피를 갖는 것으로 알려져 있습니다. 어떤 의미에서 엔트로피는 임의성이며, 이 **충실도 측정은 낮은 엔트로피에 해당**합니다. \n",
    "이제 **다양성 측면**에서 많은 샘플에서 많은 클래스가 생성되기를 원합니다. 샘플 전체에 걸쳐 클래스의 분포는 **높은 엔트로피**여야 합니다. 즉, 특정 또는 몇 개의 특정 클래스에 집중되어 있지 않아야 합니다. 이는 하나의 유형만 생성한다는 것을 의미하기 때문에 모드 붕괴를 연상시키는 경우일 것입니다. 다른 것은 아무것도 아닙니다. 이 분포는 레이블 분포 또는 y의 p라고도 합니다. 이것은 모든 레이블, 전체 데이터 세트 또는 대규모 샘플의 모든 레이블에 대한 분포입니다. 당신은 여기가 높고 여기가 낮기 때문에 이것은 혼란스러울 수 있습니다. 그러나 이 두 가지는 매우 다르다는 것을 명심하십시오. 이것이 여기서 핵심입니다.\n",
    "<img src=\"./images/C2W1.32.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "**충실도는 엔트로피가 낮고, 다양성은 엔트로피가 높다**는 개념을 사용하여 측정값을 단일 점수로 결합할 수 있습니다. 그러면 모델에 점수를 매길 수 있고 더 나아지고 있다거나, 더 나빠지고 있다고 말할 수 있기 때문에 편리합니다. 이는 높은 값을 갖는 다양성 빼기 낮은 값을 갖는 충실도 사이의 거리가 됩입니다. Inception 점수는 특히 x가 주어졌을 때 y의 p에서 y의 p로의 KL 다이버젼스(Divergence)라고 하는 것을 사용합니다. KL divergence는 본질적으로 주어진 x의 p에 대해 얼마나 많은 정보를 얻거나 얻을 수 있는지 측정하려고 시도합니다. y의 p에 대한 정보만 있고 y의 p가 다른 클래스에서 실제로 균일하다고 가정해 보겠습니다. 균일 분포와 같습니다. 그러면 x가 주어지면 y의 p에 대해 무엇을 추측할 수 있습니까? 그것은 매우 어려울 것입니다. 한편, y의 p가 정말 뾰족한 경우 X가 주어진 y의 p에 대해 무엇을 추측할 수 있습니까? 아마도 이 영역 주변에서도 뾰족한 것으로 추측할 것입니다. y의 p가 이 높은 엔트로피의 경우와 같이 본질적으로 매우 유익하지 않은 경우 많은 임의성이 있고 모두 클래스 전체에 걸쳐 있기 때문에 x가 주어지면 p의 y에 대해 많은 정보를 얻을 수 없습니다. 어느 클래스 출신인지. 그러나 여기에서 y의 p가 피크로 가득 차거나 하나의 피크로 가득 차면 x가 주어진 y의 p가 무엇인지에 대한 단서를 가질 수 있습니다. 적어도 아마 그 정점이 거기에 있을 것입니다. 동시에, x가 주어진 y의 p가 피크로 가득 차면, 모든 클래스에 걸쳐 있다고 추측하는 것보다 정확한 분포를 추측하기가 더 어렵습니다. 이 사람이 모든 클래스에 걸쳐 있다고 추측하는 것이 더 쉽습니다. \n",
    "\n",
    "자, 이것은 아주 기본적인 직관이며 KL Divergence를 완전히 이해하지 못하더라도 걱정할 필요가 없습니까? Inception 점수를 이해하기 위해 여기에서 KL Divergence는 충실도에 대한 조건부 레이블 분포가 서로에 대한 상대적 엔트로피인 다양성에 대한 한계 레이블 분포와 얼마나 다른지를 대략적으로 파악하는 것으로 생각할 수 있습니다. KL Divergence가 반대 방향으로 같지 않기 때문에 실제로 KL 거리라고 하지 않는 이유가 있습니다. 따라서 이 두 용어를 뒤집으면 실제로 동일한 값은 아니지만 그 의미에 매우 가까운 개념입니다. 결과적으로 분포가 멀리 떨어져 있을 때 높은 KL 발산을 볼 것으로 예상할 수 있습니다. 당신은 하나가 높기를 원하고 다른 하나는 낮기를 원합니다. 즉, 기본적으로 가짜 이미지마다 고유한 레이블이 있고 그 가짜들 사이에도 다양한 레이블이 존재하는 경우입니다. Notationally, 여기에서 확장하고 이 과정 밖에서 KL Divergence에 대해 더 자세히 알아볼 수 있습니다. 이는 일반적으로 기계 학습에 매우 유용한 개념이며 실제와 비교하여 모델을 평가하는 배후의 핵심 정보 이론 구성 요소입니다. 그러나 본질적으로 여기에서는 조건부 분포와 여기에서는 한계 분포를 보는 것으로 평가됩니다.\n",
    "<img src=\"./images/C2W1.33.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "인셉션 점수는 모든 이미지에 대한 합계와 모든 클래스에 대한 평균입니다. p의 엡실론, 아마도 p의 g라고 하는 것이 더 나아보입니다. 방법은 생성기의 샘플이며 여기 끝에 exponent 가 있습니다. 이것은 e의 지수에 대한 이 거대한 항을 수행하는 것과 동일합니다. 여기 있는이 지수는 실제로 이 값을 계산하거나 어떤 식으로든 KL Divergence 계산에 중요하지 않습니다. 실제로 사람이 읽을 수 있는 좋은 점수를 주기 위한 것입니다. 예를 들어 Inception Score에 대해 100이 아니라 0.000001이 아니라 이 내부 용어의 유용하지 않고 가능한 결과입니다. 따라서 수학적으로 가능한 가장 낮은 값은 0 이고 가장 높은 값은 무한대입니다. 그러나 이 경우 구현하는 동안 Inception-v3 분류기는 ImageNet에서 1,000개의 클래스로 훈련되기 때문에 가능한 가장 낮은 시작 점수는 1이고 가장 높거나 가장 좋은 점수는 존재하는 클래스 수 또는 이 경우 1,000 이 될 수 있습니다. \n",
    "이제 여기에서 점수가 높을수록 Inception Score가 더 좋습니다. 즉, 조건부 확률 분포의 엔트로피가 낮아 관련 개체 및 특징을 찾는 반면, 한계 확률(marginal probability) 분포가 높아 다양한 기능 집합을 찾을 수 있음을 의미합니다. 따라서 일반적으로 이 점수가 낮거나 나쁠 때 두 분포 모두 엔트로피가 낮고 피크가 높기 때문에 다양성이 없거나 두 분포 모두 명확한 개체가 발견되지 않고 엔트로피가 높기 때문입니다.\n",
    "\n",
    "<img src=\"./images/C2W1.34.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "하지만 짐작하셨겠지만 Inception Score를 사용하는 데에는 많은 단점이 있습니다. 첫째, 메트릭은 GAN이 각 분류기 클래스에 대해 하나의 단일 실제 이미지를 생성하므로 각 ImageNet 클래스에 대해 1000개의 이미지를 생성하면 실제로 완벽한 점수를 받기 때문에 메트릭을 악용하거나 다양성 측면에서 게임하기 쉽습니다. 그러나 이상적으로는 GAN이 각 클래스에 대해 하나의 이미지를 생성하는 것보다 더 잘 수행할 수 있습니다. 골든 리트리버 두 마리 주세요. 이것은 확실히 모드 붕괴의 한 형태이며, Inception Score에 의해 감지되지 않을 수 있습니다.\n",
    "\n",
    "<img src=\"./images/C2W1.35.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "또 다른 큰 문제는 Inception Score가 생성된 샘플만 본다는 것입니다. 여기에서 실제 샘플을 언급한 적이 없으며 생성된 샘플을 실제 이미지와 비교하지 않는다는 점을 눈치채셨을 것입니다. 이러한 프록시 통계는 다소 거리가 있고 이상주의적일 수 있으며 분류자의 작업 및 능력에 따라 달라집니다.\n",
    "<img src=\"./images/C2W1.36.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "마지막으로 분류기는 ImageNet에서 훈련되기 때문에 FID의 단점과 유사한 방식으로 값과 점수가 매우 부정확할 수 있습니다. 예를 들어 생성된 이미지에 많은 개체가 포함되어 있으면 어떻게 될까요? 다른 항목으로 가득 찬 침실이나 사무실과 같은 분류기 출력에서 ​​다른 클래스에서 높은 엔트로피를 기대할 수 있습니다. 하나의 이미지에서 다양한 클래스를 선택하기 때문에 또는 분류기가 얼굴 프로필만 생성하는 생성기와 같이 관련이 없기 때문에 분류기에 의해 감지되지 않는 많은 기능이 있는 경우에는 어떻게 될까요? 대부분 개 품종 및 기타 개체 또는 잘못된 위치에 특징이 있는 사람의 얼굴을 생성하는 생성기에 대해 훈련되었습니다. 그러나 얼굴의 구성 요소가 분류기에 의해 명확하게 발견되기 때문에 실제처럼 보입니다. 따라서 특히 공간 관계는 시작 점수에 문제가 될 수 있습니다. 훈련 데이터 세트가 ImageNet에 가까울 때만 의미가 있고 이것이 FID의 단점이기도 합니다. 이 모든 것에도 불구하고 Inception Score는 여전히 FID 이후 GAN에 대해 가장 널리 사용되는 메트릭 중 하나로 남아 있으며 주로 클래스를 지울 것으로 예상되는 조건부 GAN과 관련이 있습니다.\n",
    "\n",
    "<img src=\"./images/C2W1.37.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "#### 요약\n",
    "이제 충실도와 다양성이 낮거나 높은 엔트로피로 변환되는 방법과 인셉션 점수에 도달하기 위해 둘 다의 다이버젼스를 찾는 방법을 알았습니다. 이 점수는 꽤 인기가 있었지만 지금은 대부분 새로운 인셉션 거리로 대체되었습니다. 그러나 당신은 많은 다른 논문에서 그것을 보게 될 것입니다. 작동 방식을 아는 것이 중요합니다.\n",
    "\n",
    "* 인셉션 점수는 충실도와 다양성을 잡으려고 한다.\n",
    "* 인셉션 점수는 많은 단점이 있다.\n",
    "  - 너무 쉽게 게임을 한다.\n",
    "  - 진짜가 아닌, 단지 가짜만 살펴본다.\n",
    "  - ImageNet 이 모든 특징을 가르쳐주지는 않는다.\n",
    "* 프레세 인셉션 거리보다 나쁘다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-rebecca",
   "metadata": {},
   "source": [
    "### Sampling & Truncation\n",
    "이제 GAN의 주요 평가 방법에 대해 알게 되었습니다. \n",
    "이 비디오에서는 몇 가지 트릭에 대해 알아봅니다. \n",
    "GAN을 평가할 때 실제 데이터 세트와 가짜 데이터 세트에 대한 통계는 샘플링 측면에서 중요합니다. 그것들이 어떻게 다른지 알게 될 것이고, **더 큰 충실도나 다양성으로 전환하기 위해 훈련 후에 할 수 있는 트릭**에 대해 논의할 것입니다. \n",
    "또한 **HYPE 라고 하는 최근 개발된 인간 평가 표준**에 대해 이야기해 보겠습니다.\n",
    "\n",
    "* 진짜 대 가짜의 샘플링\n",
    "* 자르기 트릭\n",
    "* HYPE\n",
    "\n",
    "<br>\n",
    "\n",
    "샘플 크기 외에도 **FID로 평가할 때 샘플링할 이미지를 어떻게 선택**합니까? 진짜의 경우 균일한 방식의 무작위로 샘플링할 수 있지만, **가짜의 경우** 일반적으로 수행되는 작업은 **z 값의 훈련 분포 또는 z의 노이즈 벡터 p의 사전 분포를 기반으로 z 값을 샘플링**하는 것입니다. 일반적으로 사전(prior) 정규분포를 사용한 노이즈 벡터로 GAN을 훈련하기 때문에 여기에서 볼 수 있는 것과 같은 정규 분포에서 선택되는 z가 0의 $\\mu$를 중심으로 하고 표준 편차가 1입니다. 0 값에 더 가까운 벡터 값은 훈련 중에 멀리 있는 것보다 더 많이 발생합니다. 결과적으로 0에 가까운 값을 사용하여 샘플링하면 결과 이미지가 실제로 꽤 좋아 보이지만, 이는 충실도일 뿐이며, 다양성을 희생함으로 얻어진 것입니다. 여기에서 볼 수 있듯이 이 두 개는 꽤 괜찮아 보이지만 덜 다양하고, 여기에 있는 개는 조금 더 펑키해 보일 수 있습니다. **샘플링할 위치에 따라서 충실도와 다양성이 선택될 수 있습니다**. 중간에 샘플링하면 좀 더 평범해 보이는 것을 얻을 수 있습니다. 좋든 나쁘든 샘플링 기술은 실제로 평가 및 다운스트림 사용의 중요한 측면이 됩니다. FID 또는 Inception 점수와 같은 평가 메트릭은 모델 매개변수가 아니라 모델 샘플에 의해서 작동하기 때문입니다. 즉, GAN에 대한 평가는 샘플에 따라 크게 달라지므로 이것이 중요합니다.\n",
    "<img src=\"./images/C2W1.38.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "\n",
    "충실도 대 다양성에 대한 관찰에 이어 **자르기(truncation) 트릭**이라고 불리는 아주 깔끔한 샘플링 트릭이 사용됩니다. 자르기 트릭은 모델이 훈련된 후에 수행되고 충실도와 다양성을 광범위하게 상쇄하기 때문에 트릭입니다. 실제로 하는 일은 파란색으로 표시되는 이 정규 분포를 자르는 것입니다. 여기에서 꼬리 끝을 잘라 훈련 중에 사용된 노이즈 벡터를 샘플링하여 이 빨간색 곡선으로 만듭니다. 이것은 이 특정 하이퍼파라미터를 지나 여기에서 이 값을 샘플링하지 않는다는 것을 의미하고, 이 하이퍼파라미터는 여러분이 유지할 꼬리의 양을 결정하므로 여기에서 자를 수도 있고, 곡선을 더 많이 유지하기 위해 여기에서 자를 수도 있습니다. \n",
    "따라서 이미지의 품질과 사실감 정도인 **더 높은 충실도를 원한다면 0 부근에서 샘플링하고 꼬리의 더 큰 부분을 자르고 싶습니다.** 그러나 이것은 생성된 이미지의 다양성을 감소시킬 것입니다. 왜냐하면 여기에서 펑키한 날아다니는 타코가 생성되고 훈련 중에 많은 판별기 피드백을 받지 못한 기타 이상한 것들이 생성되기 때문입니다. **더 큰 다양성을 원하면 분포의 꼬리에서 더 많이 샘플링하고 더 낮은 절단 값, 절단 초매개변수 값을 원합니다.** 그러나 생성기가 노이즈 벡터를 아름답고 사실적인 이미지로 만들기 위해 가중치를 얻는 데 익숙하지 않기 때문에 이러한 이미지의 충실도도 낮아집니다. 즉, 훈련 중에 이러한 영역에서 샘플링된 노이즈 벡터에 대한 현실감에 대한 피드백을 거의 받지 못했습니다. 마지막으로, 여기와 같이 가능한 값의 집중이 없는 균일 분포와 같은 노이즈 벡터를 샘플링하는 다른 사전 노이즈 분포에 대해 모델을 확실히 훈련할 수 있습니다. 그러나 정규 분포는 부분적으로 매우 인기가 있습니다. 그러면 여기에 표시된 자르기 트릭을 사용하여 원하는 정확한 충실도와 다양성 트레이드 오프를 조정할 수 있기 때문입니다. 사람들이 다른 이전 노이즈 분포를 실험했을 때 실제로 뚜렷한 차이가 없었습니다. 예상대로 모델의 FID 점수는 더 높을 것이며, 이는 다양성이나 충실도가 부족할 때 더 나빠진다는 것을 의미합니다. 자르기 트릭을 사용할 때 샘플이 FID에서 제대로 작동하지 않을 수 있지만, 자르기 트릭을 사용하면 GAN을 적용하려는 애플리케이션에서 원하는 것과 일치할 수 있습니다. 더 높은 충실도의 이미지가 필요하고 추가 골칫거리를 원하지 않는 다운스트림입니다.\n",
    "\n",
    "<img src=\"./images/C2W1.39.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "\n",
    "FID 대신 인간의 눈에 더 보기 좋기 때문에 잘린 샘플을 사용하는 것이라 말하면, **샘플을 평가하기 위해 사람을 사용하는 것은 여전히 평가의 큰 부분이며 종종 GAN을 개발하는 프로세스의 중요한 부분**입니다. \n",
    "멋진 점은 원칙적인 크라우드 소싱 및 인식 작업을 기반으로 품질을 체계적으로 평가하는 방법이 있다는 것입니다. 사실, 최근에 개발된 GAN 충실도 표준 중 하나는 2019년에 스탠포드의 연구원들이 함께 발명한 것입니다. 그 이름은 생성 모델의 **인간 눈 지각 평가(Human eYe Perceptual Evaluation, HYPE)**를 위한 HYPE 라는 약간 건방진 이름입니다. HYPE는 Amazon Mechanical Turk의 크라우드 소스 평가자에게 일련의 이미지를 하나씩 표시하고, 평가자에게 각 이미지가 진짜인지 가짜인지 평가하도록 요청합니다. 멋진 점은 **HYPE$_time$ 이라는 HYPE의 한 버전에서는 실제로 이미지를 깜박인다는 것입니다**. 이미지가 진짜인지 가짜인지 알아낼 수 있는 임계값을 확인하기 위해 다른 길이의 milli-second 동안 깜박이게 됩니다. **생성 모델이 좋을수록 인간은 그 이미지가 가짜인지 판단하는 데 더 많은 시간이 필요**합니다. **HYPE$_\\infty$는 그 시간 임계값을 없애고, 실제로 이미지를 보기를 허용**합니다. 그러나 물론 HYPE는 평가자가 시간이 지남에 따라 가짜 이미지와 실제 이미지를 더 잘 평가함에 따라 훌륭한 품질 관리와 학습 효과를 관리할 수 있다는 것을 전제로 합니다. 이 모든 것에도 불구하고 **궁극적으로 평가는 원하는 다운스트림 작업에 따라 달라집니다**. 예를 들어, GAN이 폐렴이 있는 X-ray 를 생성하는 것이라면 의사가 실제로 그곳에 폐렴이 있음을 확인해 주길 동의할 겁니다. 하지만, 박사 학위가 없는 Amazon Mechanical Turk 의 판단이나, ImageNet 으로 사전 훈련된 분류기가 특징을 추출하여 그것이 폐렴 X선 이미지에 가까운지 여부를 알려주는 것을 원하지 않을 것입니다.\n",
    "\n",
    "<img src=\"./images/C2W1.40.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "#### 요약\n",
    "\n",
    "이제 **훈련에 사용된 z의 사전 분포를 사용하여 가짜를 샘플링하는 방법**을 알았습니다. 테스트 또는 추론 시간 동안 더 높은 충실도 또는 더 높은 다양성에 관심이 있는지 여부에 따라 샘플링 **분포의 꼬리를 조금 더 또는 조금 덜 자를 수 있는 자르기 트릭**이 있습니다. 샘플링된 이미지에서 분명히 알 수 있듯이 자동화된 평가 메트릭은 여전히 우리가 원하는 것을 정확하게 포착하지 못하지만 좋은 근사치입니다. 그렇기 때문에 **인간의 지각 평가**는 여전히 벤치마크와 표준을 설정하고 이미지를 평가하는 빠른 방법이기도 합니다. \n",
    "\n",
    "* 가짜는 훈련 또는 z의 사전 분포를 사용하여 샘플링됩니다.\n",
    "* 충실도를 높이고 다양성을 낮추려면 더 많이 자릅니다.\n",
    "* 사람의 평가가 샘플링에 아직 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4660facc",
   "metadata": {},
   "source": [
    "### 정밀도 및 재현율\n",
    "\n",
    "이번 주 자료의 마지막 부분에서는 **GAN에 사용할 수 있는 평가 개념**에 대해 배웁니다. 특히, GAN 평가의 맥락에서 **정밀도**와 **재현율**에 대해 배우게 되지만 이는 모든 생성 모델에 적용할 수 있고 그들이 충실도 및 다양성과 어떻게 관련되는 지에 대한 약간의 직관을 얻을 수 있습니다.\n",
    "\n",
    "* GAN 평가에 있어서 정밀도 및 재현율\n",
    "* 정밀도 및 재현율을 충실도 및 다양성과 연관짖기\n",
    "\n",
    "<br>\n",
    "\n",
    "최근에 추가적인 평가 측정항목이 등장했으며, 그 중 충실도와 다양성을 보다 친숙한 기계 학습 주제로 분해하는 데 특히 주목할 만하고 흥미롭게 생각되는 것은 정밀도 와 재현율 개념이다. 정밀도, 재현율 및 분류기의 개념에 익숙하다면 GAN과 같은 생성 모델에 대한 멋진 확장입니다. 모든 진짜의 공간, 여기서 **실제 분포 $P_r$**을 상상해 보십시오. 여기서 $P$는 확률 분포, $r$은 진짜를 나타냅니다. 여기 빨간색으로 표시된 $P_g$는 생성기가 생성할 수 있는 모든 것, 즉 **가짜 분포**입니다. 당신의 **GAN에서 일어날 수 있는 가장 좋은 일**은 벤다이어그램이나 모든 면에서 **$P_g$가 $P_r$과 완전히 겹치는 것**입니다. 당신은 $P_r$의 부분집합이 되기를 원하지 않고 완전히 $P_r$이 되기를 원합니다. 본질적으로 적색 $P_g$의 경우 생성된 분포는 실제 분포인 $P_r$과 완전히 같아야 합니다. 이 중요한 교차 영역이 있다는 것을 알고 있을 수 있으며 정밀도와 재현율 모두 이 교차 영역을 고려합니다.\n",
    "<img src=\"./images/C2W1.41.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "\n",
    "첫 번째 **정밀도**, 점선 안의 점에 초점을 맞춥니다. 이 점들은 모두 생성된 표본이고 채워진 점은 실제 분포와 겹치는 생성 표본이고, 채워지지 않은 점은 실제 분포와 겹치지 않는 생성 표본입니다. 정밀도는 이 교차 영역, 즉 **교차하는 가짜 예제를, 생성기가 생성할 수 있는 모든 가능한 것들의 전체 점선 영역으로 나눈 것을 측정**합니다. 직관적으로, 이것은 생성된 이미지가 이 전체 공간으로 분할된 실제 공간과 겹치기 때문에 생성된 이미지가 꽤 실제처럼 보이는 부분이 겹친다는 것을 의미합니다. 이 전체 공간에는 그의 실제 모습이 포함될 뿐만 아니라, 이 테니스 공모양 개나 이것처럼 매우 가짜로 보이는 일부 샘플도 포함됩니다. 이게 뭔지도 잘 모르겠고, 말 같기도 하고 그냥 단지 덩어리들로, 이 여분의 덩어리를 원하지 않으므로, 여기에 더 많은 것이 있을수록, 정밀도가 이러한 중첩 지점을 모든 가짜로 나눈 값이 되기 때문에 정밀도가 더 나빠집니다. 당신의 **정밀도는 본질적으로 모든 가짜들 분에 진짜처럼 보이는 가짜**입니다. 분모를 해당 겹침에 최대한 가깝게 하고 싶습니다. 완벽한 정밀도는 생성하는 모든 것이 실제처럼 보인다는 것을 의미합니다. 그러나 이것이 당신이 이 모든 것을 덮는다는 것을 의미하지는 않습니다. 여기에서 하위 집합이 될 수 있습니다. **정밀도는 충실도와 관련**이 있습니다. 모델링되었지만 **불필요한 이 추가 가짜 것들에 대한 개념이 있기 때문**입니다. **정밀도가 높을수록 생성된 모든 샘플의 품질이 높아집니다**. 자르기 트릭은 이상한 것을 정확하게 줄이는 데 도움이 될 수 있습니다. 그러나 생성된 모든 부분을 훨씬 더 작은 것으로 축소할 수 있기 때문에 재현율도 손상될 수 있습니다.\n",
    "<img src=\"./images/C2W1.42.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "\n",
    "반면에 **재현율(recall)**이라는 주제는 **진짜 샘플 전체분에 얼마나 많은 겹침이 있는 지**를 나타냅니다. 기본적으로 정밀도의 반대입니다. 여기에는 생성기가 모델링할 수 없는 것들이 포함됩니다. 이것은 실제 샘플이지만 생성기가 모델링하지 못했을 수도 있습니다. 이 당나귀와 수박으로 가득 찬 이 차를 보면, 꽤 이상한 실제 샘플처럼 보입니다. 이것은 기본적으로 **생성기가 모든 실제를 얼마나 잘 모델링할 수 있는 지에 대한 척도**이며, 우리가 이전에 보았던 생성된 모든 추가 쓰레기들은 무시되고 여기 재현율 측정에 사용되지 않습니다. **재현율은 다양성과 관련**이 있습니다. **생성자가 진짜의 모든 변형을 모델링하는지 여부를 확인할 수 있기 때문**입니다. 정밀도와 비교하기 위해 여기에서는 **모든 진짜 분에 겹친 진짜**입니다. 재현율은 생성기가 가능한 모든 진짜 이미지를 얼마나 잘 모델링할 수 있는지 이해하려고 합니다. 재현율이 좋은 모델은 노이즈 벡터의 Z 값 어딘가에서 진짜의 의미를 꽤 잘 기억하며, 모든 진짜 데이터 세트 및 그 이상을 생성할 수 있음을 의미합니다. \n",
    "그러나 일반적으로 이러한 모델은 특히 크기가 클 때 모델에 너무 많은 매개변수가 있기 때문에 판별자로부터 많은 피드백을 받지 못한 매개변수에 많은 불필요한 덩어리를 생성합니다. 이미 모든 실제를 모델링할 수 있고 축소가 필요하지 않기 때문에 불가피하게 덩어리를 생성할 것입니다. 그 모습은 $P_g$가 진짜의 상위 집합이 되어, 이와 같이 보일 것입니다. 최신 모델은 재현율과 반대로 정밀도가 떨어지는 경우가 많습니다. 이것이 바로 **절단 트릭이 다운스트림 애플리케이션이 점선 외부의 모든 추가 덩어리를 제거하는 데 유용할 수 있는 이유**입니다.\n",
    "<img src=\"./images/C2W1.43.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "#### 요약\n",
    "\n",
    "이제 생성모델의 맥락에서 정밀도와 재현율에 대해 알게 되었습니다. 이제 이미지에서 정밀도와 충실도를 연관시키고, 다양성을 재현율에 연관시킬수 있습니다.  모델은 현재 모델에 있는 수많은 매개변수 때문에 실제 이미지 분포를 재현하거나, 모델링하는데 여전히 더 나은 경향이 있습니다. 그러나 다운스트립 응용 프로그램에 자르기 트릭을 적용하여 정확도를 향상시키고 덩어리를 제거 할 수 있습니다. \n",
    "\n",
    "* 재현율의 다양성에 대한 관계는 정밀도와 충실도의 관계와 같다.\n",
    "* 모델은 재현률에서 더 좋은 경향이 있다.\n",
    "* 정밀도를 개선하기 위해서는 자르기 트릭을 사용합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
