{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1k6Y9afpxL6"
   },
   "source": [
    "# Intro\n",
    "\n",
    "[PyTorch](https://pytorch.org/)는 매우 강력한 머신러닝 프레임워크입니다. PyTorch의 핵심은 행렬을 더 높은 순위로 일반화 한 [텐서(tensor)](https://pytorch.org/docs/stable/tensors.html)입니다. 텐서의 직관적인 예는 세 가지 색상 채널이 있는 이미지입니다. 너비가 64 픽셀이고 높이가 64 픽셀인 3 채널 (빨간색, 녹색, 파란색) 이미지는 $ 3 \\times 64 \\times 64 $ 텐서입니다. 다른 모든 import 문과 함께 코드 상단 근처에 `import torch` 를 작성하여 PyTorch 프레임워크에 액세스 할 수 있습니다.\n",
    "\n",
    "이 가이드는 PyTorch의 기능을 소개하는 데 도움이 되지만 기억하는 것에 대해 너무 걱정하지 마십시오. 과제는 필요한 경우 관련 문서로 연결됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fwp6T5ZMteDC"
   },
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IvXp0rlPBqdQ"
   },
   "source": [
    "# Why PyTorch?\n",
    "\n",
    "질문 할 가치가 있는 한 가지 중요한 질문은 PyTorch가 이 과정에 사용되는 이유입니다. 오늘날 머신러닝 프레임워크의 상태를 살펴 보는 [the Gradient](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/) 에 의해 크게 분류되었습니다. 부분적으로 기사에서 강조한 바와 같이, PyTorch는 대체 프레임 워크보다 일반적으로 더 파이썬적이고 디버깅하기 쉬우며 기계 학습 연구에서 가장 많이 사용되는 언어입니다. PyTorch의 주요 대안인 Tensorflow가 PyTorch의 많은 기능을 통합하려고 시도했지만 Tensorflow의 구현에는 기사에서 강조된 몇 가지 고유한 제한이 있습니다.\n",
    "\n",
    "특히 PyTorch의 산업 사용량이 증가했지만 Tensorflow는 여전히 (현재) 산업에서 약간의 인기를 얻고 있습니다. 실제로 PyTorch를 연구에 매력적으로 만드는 기능은 교육에도 매력적이며, PyTorch에 대한 기계 학습 연구 및 실습의 일반적인 추세는 보다 적극적인 선택이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCgwdP20r1yX"
   },
   "source": [
    "# 텐서 속성\n",
    "\n",
    "목록이나 배열에서 텐서를 만드는 한 가지 방법은 `torch.Tensor` 를 사용하는 것입니다. 이 노트북에서 예제를 설정하는 데 사용되지만 코스에서 사용할 필요는 없습니다. 실제로 필요하다고 생각되면 정답이 아닐 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B0hgYekGsxlB"
   },
   "outputs": [],
   "source": [
    "example_tensor = torch.Tensor(\n",
    "    [\n",
    "     [[1, 2], [3, 4]], \n",
    "     [[5, 6], [7, 8]], \n",
    "     [[9, 0], [1, 2]]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dO4C2oft7zq"
   },
   "source": [
    "간단히 출력하여 노트북에서 텐서를 볼 수 있습니다 (일부 더 큰 텐서는 잘릴 수 있음)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "U2FKEzeYuEOX",
    "outputId": "dfa12ff7-afd1-4737-a669-54f36b4209dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[5., 6.],\n",
       "         [7., 8.]],\n",
       "\n",
       "        [[9., 0.],\n",
       "         [1., 2.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VUwlmUngw-VR"
   },
   "source": [
    "## Tensor 속성 : Device\n",
    "\n",
    "하나의 중요한 속성은 텐서의 device 입니다. 이 노트북 전체에서 CPU에 있는 텐서를 고수하게 됩니다. 그러나 과정 내내 GPU (즉, 과정에 사용할 수 있도록 제공되는 그래픽 카드)에서 텐서를 사용하게 됩니다. 텐서의 장치를 보려면`example_tensor.device` 만 작성하면 됩니다. 텐서를 새 장치로 이동하려면`new_tensor = example_tensor.to(device)`를 작성하면 됩니다. 여기서 device는`cpu` 또는`cuda` 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R7SF44_Vw9h0",
    "outputId": "57f90e38-f9e1-4115-8f27-ebe651d5b2fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FkfySyFduHQi"
   },
   "source": [
    "## Tensor 속성 : Shape\n",
    "\n",
    "그리고 numpy를 사용했다면 익숙한 `example_tensor.shape`를 사용하여 텐서의 모양을 인쇄하여 각 차원의 요소 수를 얻을 수 있습니다. 예를 들어, 이 텐서는 $3\\times2\\times2$ 텐서입니다. 3 개의 요소가 있고 각 요소는 $2\\times2$ 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DKmfzpOBun0t",
    "outputId": "883009b6-7300-4329-f9ec-df99cc36d846"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aL954xmAuq4b"
   },
   "source": [
    "`example_tensor.shape[n]` 또는 이와 동등한 `example_tensor.size(n)` 를 사용하여 특정 차원 $n$의 크기를 얻을 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7IKy3BB8uqBo",
    "outputId": "7fac1275-132f-4d2b-bf63-73065a2aea6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape[0] = 3\n",
      "size(1) = 2\n"
     ]
    }
   ],
   "source": [
    "print(\"shape[0] =\", example_tensor.shape[0])\n",
    "print(\"size(1) =\", example_tensor.size(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3pzzG8bav5rl"
   },
   "source": [
    "마지막으로 차원 수(rank) 또는 요소의 수를 가져 오는 것이 유용한 경우가 있습니다. 다음과 같이 수행 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "l_j9qTwyv41-",
    "outputId": "5921cbd1-19a2-4543-9488-3f72c0cb4970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank = 3\n",
      "Number of elements = 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Rank =\", len(example_tensor.shape))\n",
    "print(\"Number of elements =\", example_tensor.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gibyKQJQzLkm"
   },
   "source": [
    "# 인덱싱 텐서\n",
    "\n",
    "numpy와 마찬가지로 특정 요소 또는 텐서 요소의 하위 집합에 액세스 할 수 있습니다. $n$-번째 요소에 액세스하려면 `example_tensor[n]`을 작성하면 됩니다. 일반적으로 Python과 마찬가지로 이러한 차원은 0-부터 시작하는 인덱스입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "F87bFA5SzNz7",
    "outputId": "1b0a8381-6fd8-40b4-a5c8-88cc80029f8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1CegGw5wzpGa"
   },
   "source": [
    "또한 $i$ 번째 예제의 $j$ 번째 차원에 액세스하려면 `example_tensor [i, j]`를 작성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bl1JSZcRz0xn",
    "outputId": "7f98e47b-66cb-4927-b784-7e4bcb9eb687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor[1, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dyQRCRIa4NaY"
   },
   "source": [
    "텐서에서 Python 스칼라 값을 얻으려면 `example_scalar.item()`을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e56KSJOq4YOE",
    "outputId": "29e1fd13-32df-40c5-e558-3193fa5da629"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor[1, 1, 0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wZdMEQfu0A7h"
   },
   "source": [
    "또한 `x [:, i]`를 사용하여 열의 i 번째 요소를 인덱싱 할 수 있습니다. 예를 들어 `example_tensor` 에 있는 각 요소의 왼쪽 상단 요소(각 행렬의 `0, 0` 요소)를 원하면 다음과 같이 작성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x2cFxJx50eGH",
    "outputId": "e66eade9-4b4b-4c7a-ea99-a83195d10541"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 5., 9.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor[:, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-rTBP-1whd2"
   },
   "source": [
    "# 텐서 초기화\n",
    "\n",
    "PyTorch 에서 새 텐서를 만드는 방법은 여러 가지가 있지만, 이 과정에서 가장 중요한 방법은 다음과 같습니다.\n",
    "\n",
    "[`torch.ones_like`](https://pytorch.org/docs/master/generated/torch.ones_like.html) :`example_tensor`와 모양과 장치가 동일하며, 모든 요소가 1인 텐서를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "g7gbs4AnwlIo",
    "outputId": "b0c67ed9-e33f-47d6-d95c-e53bc4f90dec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(example_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_aIbSlaJy9Z0"
   },
   "source": [
    "[`torch.zeros_like`](https://pytorch.org/docs/master/generated/torch.zeros_like.html): `example_tensor`와 모양과 장치가 동일하며, 모든 요소가 0인 텐서를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "X4cWQduzzCd8",
    "outputId": "dbc8a5fa-8db1-4f6d-e38e-d1deb982ff36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(example_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsOmgS1izDS_"
   },
   "source": [
    "[`torch.randn_like`](https://pytorch.org/docs/stable/generated/torch.randn_like.html): `example_tensor`와 모양과 장치가 동일한 [Normal (또는 Gaussian) 분포](https://en.wikipedia.org/wiki/Normal_distribution)에서 샘플링 된 모든 요소로 텐서를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "2hto51IazDow",
    "outputId": "cb62a68a-6171-4d1e-eb9b-f31784464aac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8422,  0.2482],\n",
       "         [-0.5304,  1.0010]],\n",
       "\n",
       "        [[ 0.7214,  0.5954],\n",
       "         [ 0.1338, -0.0621]],\n",
       "\n",
       "        [[-0.6337,  0.6675],\n",
       "         [ 1.2811, -0.0149]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn_like(example_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXp0i5Cf6AGj"
   },
   "source": [
    "때로는 (예상보다 덜 자주), `ones_like` 또는 `randn_like`에 대한 참조 용 텐서없이 모양과 장치만 알고 있는 텐서를 초기화해야 할 수도 있습니다. 이 경우 다음과 같이 $2x2$ 텐서를 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RZRqt3-S6cUZ",
    "outputId": "7bef97cc-a303-4200-c0f8-ef9bf3cb4996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4556, 0.3286],\n",
       "        [1.4494, 1.0598]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 2, device='cpu') # Alternatively, for a GPU tensor, you'd use device='cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTkmDwVsrM6R"
   },
   "source": [
    "# 기본 함수\n",
    "\n",
    "PyTorch 를 사용하기 위해 알아야 할 몇 가지 기본 함수다 있습니다. numpy 에 익숙하다면 일반적으로 사용되는 모든 함수가 PyTorch 에 존재하며 일반적으로 동일한 이름을 사용합니다. 단순히 `c * example_tensor`를 작성하여 스칼라 $c$ 로 요소 별 곱셈/나눗셈을 수행하고 `example_tensor + c` 를 작성하여 스칼라별로 요소 별 덧셈/빼기를 수행 할 수 있습니다.\n",
    "\n",
    "대부분의 연산은 PyTorch에서 제자리에 있지 않습니다. 즉, 원래 변수의 데이터를 변경하지 않는다는 의미입니다 (그러나 원하는 경우 변경된 데이터에 동일한 변수 이름을 다시 할당 할 수 있습니다 (예 : `example_tensor = example_tensor + 1`))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "FpfwOUdopsF_",
    "outputId": "32347400-2e6a-40c6-e6f1-21e6aacde795"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -8.,  -6.],\n",
       "         [ -4.,  -2.]],\n",
       "\n",
       "        [[  0.,   2.],\n",
       "         [  4.,   6.]],\n",
       "\n",
       "        [[  8., -10.],\n",
       "         [ -8.,  -6.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(example_tensor - 5) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uciZnx4b3UjX"
   },
   "source": [
    "[`example_tensor.mean()`](https://pytorch.org/docs/stable/generated/torch.mean.html) 또는 [`example_tensor.std()`](https://pytorch.org/docs/stable/generated/torch.std.html)를 사용하여 텐서의 평균 또는 표준 편차를 계산할 수 있습니다. `."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0ELXUKG7329z",
    "outputId": "720dd190-7dd4-43f1-e53c-cba4263eb2be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor(4.)\n",
      "Stdev: tensor(2.9848)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean:\", example_tensor.mean())\n",
    "print(\"Stdev:\", example_tensor.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QsyTRym32SX"
   },
   "source": [
    "특정 차원을 따라 평균 또는 표준 편차를 찾을 수도 있습니다. 이렇게 하려면 해당 차원에 해당하는 숫자를 함수에 간단히 전달할 수 있습니다. 예를 들어, $ 3 \\times 2 \\times 2 $ `example_tensor`의 평균 $ 2 \\times 2 $ 행렬을 얻으려면 다음과 같이 작성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "eCJl3Im25B9k",
    "outputId": "4bd9decd-579e-462c-bde1-ee8d9d1b2061"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0000, 2.6667],\n",
       "        [3.6667, 4.6667]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor.mean(0)\n",
    "\n",
    "# Equivalently, you could also write:\n",
    "# example_tensor.mean(dim=0)\n",
    "# example_tensor.mean(axis=0)\n",
    "# torch.mean(example_tensor, 0)\n",
    "# torch.mean(example_tensor, dim=0)\n",
    "# torch.mean(example_tensor, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vb-_5ubc8t97"
   },
   "source": [
    "PyTorch는 다른 많은 강력한 함수들을 가지고 있지만, 신경망 모듈 (`torch.nn`) 외부에서 이 과정에 필요한 모든 PyTorch 함수들이 이것들 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RtWjExD69JEs"
   },
   "source": [
    "# PyTorch 신경망 모듈 (`torch.nn`)\n",
    "\n",
    "PyTorch는`torch.nn` 모듈에 강력한 클래스가 많이 있습니다 (보통 단순히`nn`로 가져옴). 이러한 클래스를 사용하면 특정 방식으로 텐서를 변환하는 새 함수를 만들 수 있으며, 종종 여러 번 호출 될 때 정보를 유지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYrgloYo_slC"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uyCPVmTD_kkl"
   },
   "source": [
    "## `nn.Linear`\n",
    "\n",
    "선형 레이어를 만들려면 입력 차원 수와 출력 차원 수를 전달해야 합니다. `nn.Linear(10, 2)`로 초기화 된 선형 객체는 $ n \\times 10 $ 행렬을 받아 $ n \\times 2 $ 행렬을 반환합니다. 여기서 모든 $ n $ 요소는 동일한 선형 변환을 수행했습니다. 예를 들어 $ Ax + b $ 작업을 수행하는 선형 층을 초기화 할 수 있습니다. 여기서 $ A $ 및 $ b $는 [`nn.Linear()`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) 객체."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "pNPaHPo89VrN",
    "outputId": "c14dc316-ae68-49d3-a8eb-8ad6e1464f01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6986, -0.6680],\n",
       "        [ 0.3313, -0.6365],\n",
       "        [-1.1942,  0.5160]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(10, 2)\n",
    "example_input = torch.randn(3, 10)\n",
    "example_output = linear(example_input)\n",
    "example_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YGNULkJR_mzn"
   },
   "source": [
    "## `nn.ReLU`\n",
    "\n",
    "[`nn.ReLU()`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)는 텐서를받을 때 ReLU 활성화 함수을 수행 할 객체를 생성합니다. 이것은 강의에서 더 검토 될 것이지만 본질적으로 ReLU 비선형성은 텐서의 모든 음수를 0 으로 설정합니다. 일반적으로 가장 단순한 신경망은 일련의 선형 변환으로 구성되며 각 변환은 활성화 함수가 뒤 따릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "nGxVFS3nBASc",
    "outputId": "d5f57584-1bad-4803-ba8c-b69881db4a1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6986, 0.0000],\n",
       "        [0.3313, 0.0000],\n",
       "        [0.0000, 0.5160]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "relu_output = relu(example_output)\n",
    "relu_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KzfOEZ03AJzA"
   },
   "source": [
    "## `nn.BatchNorm1d`\n",
    "\n",
    "[`nn.BatchNorm1d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html) 는 배치 간에 일관된 평균 및 표준 편차를 갖도록 $ n $ 입력 배치의 크기를 조정하는 정규화 기술입니다.\n",
    "\n",
    "이름에 '1d'로 표시된 것처럼 이는 입력 세트가 예상되는 상황을 위한 것이며, 각 입력은 단순한 숫자 목록입니다. 즉, 각 입력은 행렬이나 고차원 텐서가 아닌 벡터입니다. 각각 고차원 텐서인 이미지 세트의 경우 [`nn.BatchNorm2d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)를 사용합니다. 이 페이지의 뒷부분에서 설명합니다.\n",
    "\n",
    "`nn.BatchNorm1d`는 배치에 있는 각 객체의 입력 차원 수(각 예제 벡터의 크기) 인수를 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "O4tYsi9-G9vM",
    "outputId": "ba61d37c-a8af-4663-fcc2-1691c6d241de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2452, -0.7070],\n",
       "        [-0.0421, -0.7070],\n",
       "        [-1.2031,  1.4141]], grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchnorm = nn.BatchNorm1d(2)\n",
    "batchnorm_output = batchnorm(relu_output)\n",
    "batchnorm_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMZewDz9Idr1"
   },
   "source": [
    "## `nn.Sequential`\n",
    "\n",
    "[`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) 는는 일련의 작업을 수행하는 단일 작업을 만듭니다. 예를 들어 다음과 같이 배치 정규화를 사용하여 신경망 계층을 작성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "R3GhASjyJt3N",
    "outputId": "3ef779ca-a17b-42fd-f2e5-fbb5fdc60b13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \n",
      "tensor([[ 0.9555,  1.8611,  0.4448,  1.0188,  1.3745],\n",
      "        [ 0.7405,  1.8937,  1.2454,  0.3093, -0.2776],\n",
      "        [ 2.1763,  0.1092,  0.9367, -1.3304,  0.6947],\n",
      "        [ 0.0491,  0.4316,  2.4480,  0.8016,  1.5365],\n",
      "        [ 0.6871,  1.3320,  1.6170, -0.4543,  0.9606]])\n",
      "output: \n",
      "tensor([[0.0000, 1.5562],\n",
      "        [1.6356, 0.0000],\n",
      "        [0.5181, 0.0000],\n",
      "        [0.0000, 0.7430],\n",
      "        [0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mlp_layer = nn.Sequential(\n",
    "    nn.Linear(5, 2),\n",
    "    nn.BatchNorm1d(2),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "test_example = torch.randn(5,5) + 1\n",
    "print(\"input: \")\n",
    "print(test_example)\n",
    "print(\"output: \")\n",
    "print(mlp_layer(test_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SToQiSv5K5Yb"
   },
   "source": [
    "# 최적화\n",
    "\n",
    "본질적으로 모든 기계 학습 프레임 워크의 가장 중요한 측면 중 하나는 자동 미분 라이브러리입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r4GZFCZ0QqI1"
   },
   "source": [
    "## 최적화 도구\n",
    "\n",
    "PyTorch에서 최적화도구를 생성하려면 종종`optim`으로 가져 오는`torch.optim` 모듈을 사용해야합니다. [`optim.Adam`](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam)은 Adam 최적화 프로그램에 해당합니다. 옵티마이저 객체를 생성하려면 최적화 할 매개 변수와 학습률 `lr` 및 옵티마이저와 관련된 기타 매개 변수를 전달해야 합니다.\n",
    "\n",
    "모든 `nn` 객체의 경우 다음과 같이 `parameters()`메서드를 사용하여 매개 변수에 목록으로 액세스 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIcCbs35K4wY"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "adam_opt = optim.Adam(mlp_layer.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BsPFZu2M0Xx"
   },
   "source": [
    "## 훈련 루프\n",
    "\n",
    "PyTorch의 (기본) 교육 단계는 네 가지 기본 부분으로 구성됩니다.\n",
    "\n",
    "\n",
    "1. `opt.zero_grad()`를 사용하여 모든 그라디언트를 0으로 설정\n",
    "2.  손실 `loss` 계산\n",
    "3. `loss.backward()`를 사용하여 손실에 대한 기울기를 계산\n",
    "4. `opt.step()`을 사용하여 최적화 중인 매개 변수를 업데이트\n",
    "\n",
    "다음 코드와 같이 보일 수 있습니다 (여러 번 실행하면 손실이 줄어듭니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zm6lPx4sOJht",
    "outputId": "c21672bd-a306-42ab-face-9a299511a059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7513, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train_example = torch.randn(100,5) + 1\n",
    "adam_opt.zero_grad()\n",
    "\n",
    "# We'll use a simple loss function of mean distance from 1\n",
    "# torch.abs takes the absolute value of a tensor\n",
    "cur_loss = torch.abs(1 - mlp_layer(train_example)).mean()\n",
    "\n",
    "cur_loss.backward()\n",
    "adam_opt.step()\n",
    "print(cur_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDjhZBCeTc6o"
   },
   "source": [
    "## `requires_grad_()`\n",
    "\n",
    "또한 PyTorch에`example_tensor.requires_grad_()`라고 말하여 생성한 텐서에 대한 그래디언트를 계산해야 한다고 말할 수 있습니다. 즉, PyTorch가 일반적으로 특정 텐서에 대한 `grad`를 저장하지 않더라도 지정된 텐서에 대한 `grad`를 저장합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mB22ovHyUEvH"
   },
   "source": [
    "## `with torch.no_grad():`\n",
    "\n",
    "PyTorch는 일반적으로 텐서에 대한 일련의 작업을 진행하면서 그래디언트를 계산합니다. 특히 평가를 수행하는 경우에는 종종 불필요한 계산과 메모리를 차지할 수 있습니다. 그러나 코드 조각에서 그라디언트가 계산되지 않도록 `with torch.no_grad()`로 코드를 감쌀 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kowb1M425CE_"
   },
   "source": [
    "\n",
    "## `detach():`\n",
    "\n",
    "때로는 그라디언트를 계산하지 않고 텐서의 값을 계산하고 사용하기도 합니다. 예를 들어, A와 B라는 두 개의 모델이 있고 B를 통한 기울기를 계산하지 않고 B의 출력과 관련하여 A의 매개 변수를 직접 최적화하려는 경우 B의 분리된 출력을 A에 공급할 수 있습니다. 효율성 또는 주기적 종속성 (즉, A가 B에 종속됨)을 포함하여 이를 수행하려는 여러 가지 이유가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9HY2wgKLOr-"
   },
   "source": [
    "# 새로운`nn` 클래스\n",
    "\n",
    "`nn` 모듈을 확장하는 새 클래스를 만들 수도 있습니다. 이러한 클래스의 경우`self.layer` 또는 `self.param`과 같은 모든 클래스 속성은 자체가 `nn` 객체이거나 다음으로 초기화되는 `nn.Parameter`에 감싸진 텐서인 경우 자동으로 매개 변수로 처리됩니다. 클래스.\n",
    "\n",
    "`__init__` 함수는 객체가 생성 될 때 일어날 일을 정의합니다. 예를 들어`WellNamedClass`와 같은 클래스의 init 함수의 첫 번째 줄은`super (WellNamedClass, self).__init__()`여야합니다.\n",
    "\n",
    "`forward` 함수는`model(x)`에서와 같이 객체 `model`을 만들고 텐서 `x`를 전달하면 실행되는 것을 정의합니다. 함수 시그니처 `(self, x)`를 선택하면 forward 함수를 호출 할 때마다 두 가지 정보가 제공됩니다. 모든 매개 변수에 액세스 할 수있는 객체에 대한 참조 인 `self`, 그리고 `y`를 반환하려는 현재 텐서인 `x`.\n",
    "\n",
    "한 클래스는 다음과 같이 보일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WOip473tQs-d"
   },
   "outputs": [],
   "source": [
    "class ExampleModule(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super(ExampleModule, self).__init__()\n",
    "        self.linear = nn.Linear(input_dims, output_dims)\n",
    "        self.exponent = nn.Parameter(torch.tensor(1.))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "\n",
    "        # This is the notation for element-wise exponentiation, \n",
    "        # which matches python in general\n",
    "        x = x ** self.exponent \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4CUFH_GS5UY"
   },
   "source": [
    "그리고 다음과 같이 매개 변수를 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "YuelIiE4S3KR",
    "outputId": "27a52620-ca40-4dc8-dff5-4f3a56ba0e5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor(1., requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2790, -0.2090,  0.2901,  0.1242, -0.1559,  0.2492, -0.2658,  0.2615,\n",
       "          -0.1367,  0.0855],\n",
       "         [ 0.0518, -0.0859, -0.1407,  0.2637, -0.1023,  0.1330,  0.2676, -0.0827,\n",
       "           0.1091, -0.1994]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0294, 0.2475], requires_grad=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_model = ExampleModule(10, 2)\n",
    "list(example_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1F7E1wKN5tez"
   },
   "source": [
    "다음과 같이 이름도 인쇄 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "dYTuTDsQ5pnY",
    "outputId": "6635a493-7318-4688-bd18-bfba41d43e9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exponent',\n",
       "  Parameter containing:\n",
       "  tensor(1., requires_grad=True)),\n",
       " ('linear.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2790, -0.2090,  0.2901,  0.1242, -0.1559,  0.2492, -0.2658,  0.2615,\n",
       "           -0.1367,  0.0855],\n",
       "          [ 0.0518, -0.0859, -0.1407,  0.2637, -0.1023,  0.1330,  0.2676, -0.0827,\n",
       "            0.1091, -0.1994]], requires_grad=True)),\n",
       " ('linear.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0294, 0.2475], requires_grad=True))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(example_model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWPoIqX2UsaH"
   },
   "source": [
    "다음은 실행 중인 클래스의 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7NXwbg5tUroC",
    "outputId": "0836e447-7c37-464e-b196-048ae0a0cc73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0133,  0.4761],\n",
       "        [ 0.0348, -0.2413]], grad_fn=<PowBackward1>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(2, 10)\n",
    "example_model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Ocol8DABScy"
   },
   "source": [
    "# 2D 연산\n",
    "\n",
    "첫 번째 강의에서는 이러한 항목이 필요하지 않으며, 각각의 이론은 이후 강의에서 더 많이 검토되지만 다음은 빠른 참조입니다.\n",
    "\n",
    "\n",
    "* 2D 컨볼루션 : [`nn.Conv2d`](https://pytorch.org/docs/master/generated/torch.nn.Conv2d.html)에는 입력 및 출력 채널 수와 커널 크기가 필요합니다.\n",
    "* 2D 전치 컨볼루션 (일명 디컨볼루션) : [`nn.ConvTranspose2d`](https://pytorch.org/docs/master/generated/torch.nn.ConvTranspose2d.html) 에는 다음과 같이 커널 크기와 함께 입력 및 출력 채널 수도 필요합니다.\n",
    "* 2D 배치 정규화 : [`nn.BatchNorm2d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)에는 입력 차원 수가 필요합니다.\n",
    "* 이미지 크기 조정 : [`nn.Upsample`](https://pytorch.org/docs/master/generated/torch.nn.Upsample.html)에는 최종 크기 또는 배율이 필요합니다. 또는 [`nn.functional.interpolate`](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.interpolate)는 동일한 인수를 사용합니다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Intro to PyTorch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
