{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "minimal-singing",
   "metadata": {},
   "source": [
    "Generative Adversarial Networks 또는 GAN의 첫 수업에 오신 것을 환영합니다. 이번 주에는 GAN이 달성한 몇 가지 놀라운 업적을 보게 될 것입니다. 여기에서 약간의 눈을 즐겁게 해주는 이미지들을 볼 수 있게 될 것입니다. 시간이 지남에 따라 점점 더 좋아지는 과정도 볼 수 있습니다. GAN은 무감독(unsupervised) 학습기술입니다. 여러분들은 분류기(classifier)와 같은 감독(supervised) 학습기술을 많이 보았을 수 있읍니다만, GAN은 약간 다릅니다. 이번 주에는 GAN과 GAN 뒤에 두 가지 모델인 생성기와 판별기가 있는 방법에 대해 약간의 직관을 얻을 것입니다. 그들은 실제로 서로 싸우는데, 이 싸움을 통해서 사실적인 이미지를 생성하는 모델을 만들게됩니다. 이번 주는 이진 교차 엔트로피 손실에 대한 검토와 이번 주의 과제를 다루기 전에 이에 익숙해질 수 있도록 약간의 PyTorch 사용법도 배워볼 수 있습니다. 이번 주 과제에서는 첫 번째 GAN을 구축하게 될 것입니다. 시작하겠습니다.\n",
    "\n",
    "\n",
    "## 생성적 모델(Generative Models)\n",
    "\n",
    "이 강의에서 사실적인 이미지, 음악 및 기타 다양한 것들을 생성할 수 있는 모델을 구축하는 방법을 볼 수 있습니다. 이 섹션에서는 GAN 및 관련 모델들의 작동 방식에 대한 직관을 얻을 것입니다. 주말이 되면 손으로 쓴 숫자를 생성하는 자신만의 GAN을 구축하게 됩니다. 이 섹션에서는 생성 모델이 무엇인지, GAN이 어떤 유형인지, 그리고 이러한 모델이 이미 알고 있는 다른 신경망 모델과 어떻게 비교되는지 소개하겠습니다. 또한 가장 인기 있는 두 가지 생성 모델 아키텍처에 대해서도 이야기하겠습니다.\n",
    "\n",
    "* 생성적 모델(generative models) 이란?\n",
    "* 생성적 모델의 유형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-crash",
   "metadata": {},
   "source": [
    "### 생성적 모델 vs. 판별적 모델 (Generative Models vs. Discriminative Models)\n",
    "\n",
    "여러분들은 아마 판별적 모델에 익숙할 수 있지만, 머신 러닝 또는 ML의 더 큰 맥락에서 이들이 어디에 들어 맞는지 모를 수 있습니다. 판별적 모델은 일반적으로 기계 학습에서 분류에 사용되는 모델입니다. 그들은 개와 고양이와 같은 클래스를 구별하는 방법을 배우며, 종종 분류기(classifier)라고 불립니다. \n",
    "\n",
    "판별적 모델은 젖은 코를 가지고 있는지 여부와 같은 일련의 특징 $X$를 취하고, 이러한 특징으로부터 이미지가 개인지 고양이인지에 대한 범주를 결정합니다. 다시 말해서, 그들은 일련의 특징 $X$가 젖은 코를 가지고 있는 것으로 주어진 클래스 $Y$의 확률을 모델링하려고 시도하지만, 고양이 소리를 내지 않는다면 아마도 개일 것입니다. \n",
    "\n",
    "반면에 생성적 모델은 일부 클래스를 사실적으로 표현하는 방법을 배우려고 합니다. 예를 들어, 여기에서 볼 수 있는 강아지의 사실적인 그림이 있습니다. 그들은 여기에서 코로 표시되는 임의의 입력을 취합니다. 값은 3, 임의의 숫자, -5, 2.6 또는 실제로 모든 값의 벡터를 취할 수 있습니다. 요점은 노이즈가 생성 모델에 들어가는 임의의 값 집합을 나타냅니다. 생성 모델은 때때로 개와 같은 클래스 $Y$를 사용합니다. 이러한 입력에서 목표는 사실적인 개처럼 보이는 일련의 특징 $X$를 생성하는 것입니다. 젖은 코나 혀가 튀어나와 있는 등의 특징이 있는 개의 이미지입니다. 처음에 이 잡음이 왜 필요한지 궁금할 것입니다. 그냥 \"이봐, 나를 위해 개를 만들어줘\"라고 말하면 개를 생성할 수 있습니다. 생성되는 것이 매번 실제로 같은 개가 아니라는 것을 확인하기 위해 노이즈가 필요하게 되며, 이 주제에 대하여는 곧 배워보게 될 겁니다. 하나의 개만을 생성하는 것은 재미도 없고 약간 무의미하기 때문입니다. 지금은 이것을 입력으로 들어가는 임의의 노이즈로 생각하십시오. 더 일반적으로, 생성 모델은 젖은 코, 튀어나온 혀, 때로는 뾰족한 귀를 갖는 다양한 특징들 갖는 $X$의 확률 분포를 포착하려고 합니다. 노이즈가 추가되면 이 모델은 이 클래스 $Y$의 사실적이고 다양한 표현을 생성합니다. 실제로, 개의 클래스 하나만 생성한다면 $Y$에 대한 이 조건화가 필요하지 않을 것이며 대신 모든 특징 $X$에 대한 확률일 뿐입니다. 이것들을 나란히 비교하면 판별적 모델과 생성적 모델이 실제로 약간 가깝다는 것을 알 수 있습니다.\n",
    "\n",
    "<img src=\"./images/C1W1.01.png\" width=\"700\">\n",
    "\n",
    "생성 모델의 예로서 생성 모델을 잘 실행하면 이 페키니즈와 다른 실행에서는 티베트 마스티프의 사진을 얻을 수 있습니다. 제한 없이 여러 번 계속 실행하면 생성 모델이 훈련된 데이터 세트를 나타내는 더 많은 이미지를 얻게 됩니다. 물론 많은 래브라도 리트리버들이 생성될 수도 있습니다.\n",
    "\n",
    "<img src=\"./images/C1W1.02.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-powder",
   "metadata": {},
   "source": [
    "### 생성적 모델\n",
    "\n",
    "#### Variational Autoencoders (VAE)\n",
    "생성적 모델의 종류는 여러 가지가 있는데 가장 인기 있는 것만 간략히 소개해 드리겠습니다. Variational autoencoder 또는 줄여서 VAE 와 GAN. VAE는 인코더와 디코더의 두 가지 모델과 함께 작동하며 일반적으로 신경망입니다. 그들은 내가 그린 강아지의 실제 이미지와 같은 사실적인 이미지를 인코더에 입력하여 먼저 학습합니다. 그런 다음 인코더의 작업은 이 엉뚱한 잠재 공간에서 해당 이미지를 나타내는 좋은 방법을 찾는 것입니다. 바로 여기에서 장소를 찾습니다. 잠재 공간의 이 지점이 숫자 6.2, -3, 21의 벡터로 표현될 수 있다고 가정해 봅시다. VAE가 지금 하는 일은 이 잠재 표현이나 그것에 가까운 지점을 가져와 디코더에 넣는 것입니다. 디코더의 목표는 인코더가 이전에 본 사실적인 이미지를 재구성하는 것입니다. 그것은 디코더가 이미 꽤 좋은 훈련을 받았다고 가정합니다. 그러나 처음에는 디코더가 이미지를 재구성할 수 없으며 생성된 개가 사악한 눈을 가질 수 있습니다. 훈련 후에 우리는 실제로 인코더를 잘라내고 여기와 같은 잠재 공간에서 임의의 지점을 선택할 수 있습니다. 그러면 디코더는 개의 사실적인 이미지를 생성하는 방법을 배울 것입니다. 방금 설명한 것은 주로 변형(varitional) 오토인코더에서의 오토인코더 부분입니다. 변형(variational) 부분은 실제로 이 전체 모델과 훈련 과정에 약간의 노이즈를 주입합니다. 인코더가 이미지를 해당 잠재 공간의 단일 지점으로 인코딩하도록 하는 대신 인코더는 실제로 이미지를 전체 분포에 인코딩한 다음 해당 분포의 한 지점을 샘플링하여 디코더에 공급하여 사실적인 이미지를 생성합니다. 이 분포에서 다른 지점을 샘플링할 수 있으므로 약간의 노이즈가 추가됩니다.\n",
    "\n",
    "<img src=\"./images/C1W1.03.png\" width=\"700\">\n",
    "\n",
    "\n",
    "#### Generative Adversarial Networks (GAN)\n",
    "GAN은 다소 다른 방식으로 작동합니다. 그것들은 다시 두 가지 모델로 구성되어 있지만 이제 디코더와 같은 이미지를 생성하는 생성기와 이 안에 숨겨진 판별 모델인 판별기가 있습니다. 생성기는 이전에 보았듯이 임의의 노이즈 입력(예: 1.2, 3, 음의 5)을 벡터로 받아 이 생성기에 입력합니다. 물론 선택적인 큭래스는 dog 이지만, dog를 생성하는 경우에는 굳이 입력할 필요가 없습니다. 결과적으로 시간이 지남에 따라 동일한 개를 생성할 수 있으며 물론 처음에는 악한 모양의 dog 일 수도 있습니다. 어떤 의미에서 생성기의 역할은 VAE의 디코더와 매우 유사합니다. 다른 점은 이번에는 생성기에 입력되는 노이즈 벡터가 어떻게 생겼는지 결정하는 가이드 인코더가 없다는 것입니다. 대신, 가짜와 진짜 이미지를 보고 동시에 어떤 것이 진짜이고 어떤 것이 가짜인지 알아내려고 하는 판별자가 있습니다. 시간이 지남에 따라 각 모델은 서로를 이기려고 합니다. 이러한 모델은 생성적 적대 네트워크라는 이름으로 서로 경쟁하는 이유 때문에 적대적(adversarial)이라고 불립니다. 시간이 지남에 따라 근육이 서로 경쟁하고 학습하면서 두 번째 모델인 판별기가 더 이상 필요하지 않은 지점에 도달할 때까지, 그리고, 생성기가 임의의 노이즈를 받아들여 현실적인 이미지를 생성하는 지점에 도달할 때까지 근육이 성장하는 것을 상상할 수 있습니다. 예를 들어, 무작위 수 -5, 6.2, 8로 구성된 벡터는 이 귀여운 래브라도 리트리버를 생성할 수 있습니다. 이 전문화 과정에서 여러분은 GAN에 초점을 맞추게 될 것이지만, 흥미롭다면 더 많은 내용과 VAE를 읽으십시오. 아직 GAN이 어떻게 작동하는지 잘 이해하지 못하더라도 걱정하지 마십시오. 이번 주에 나올 비디오에서 그들의 아키텍처와 그들이 배우는 방식에 대해 더 깊이 파고들 것입니다. 요약하면, 생성적 모델은 사진처럼 보이는 그림을 그릴 수 있는 예술가와 같이 실제적인 예를 생성하는 방법을 배웁니다. 한편, 판별적 모델은 다른 클래스를 구별합니다.\n",
    "\n",
    "<img src=\"./images/C1W1.04.png\" width=\"700\">\n",
    "\n",
    "### 요약\n",
    "요약하면, 생성적 모델은 방금 본 귀여운 강아지의 사진을 생성하는 것과 같은 실제적인 예를 생성하는 방법을 배웁니다. 생성적 모델은 사진처럼 사실적인 예술을 만드는 방법을 배우려고 노력하는 예술가입니다. 한편, 판별적 모델은 개 또는 고양이와 같은 다른 클래스를 구별합니다. 그러나 물론 판별 모델은 클래스가 실제 및 가짜인 판별기와 같은 생성 모델의 하위 구성요소가 될 수 있음을 확인했습니다. 생성적 모델에는 여러 종류가 있지만 이 전문 분야에서는 GAN을 공부하게 됩니다. 이번 주말에 손으로 쓴 숫자를 생성할 수 있는 자신만의 GAN을 구축하게 될 것입니다. 얼마나 멋진가요? 준비하세요.\n",
    "\n",
    "* 생성적 모델은 실제적인 예를 생성하도록 학습한다.\n",
    "\n",
    "* 판별적 모델은 클래스들을 판별한다. (GAN 모델의 일부분으로 활용된다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-algorithm",
   "metadata": {},
   "source": [
    "## Real Life GANs\n",
    "GAN은 2014년부터 사용되었지만 이미 여러 작업에서 매우 인상적인 성능을 달성했습니다. 그들의 결과 중 일부를 아직 보지 못했다면, 이번 색션이 재미있을 겁니다. 이 비디오에서는 사실적인 사람의 얼굴 생성 및 유명 작품의 애니메이션과 같은 GAN의 멋진 응용 프로그램을 보여 드리겠습니다. 그런 다음 주요 회사에서 사용하는 놀라운 프로젝트 중 일부를 보게 될 것입니다.\n",
    "* Cool applications of GANS\n",
    "* Major companies using them\n",
    "\n",
    "### GANs Over Time\n",
    "이 트윗은 GAN의 창시자로 널리 알려진 Ian Goodfellow의 것입니다. 이는 GAN이 수년에 걸쳐 개선된 비율에 대한 놀라운 시각화를 보여줍니다. GAN이 2014년 흑백의 다소 비인간적인 얼굴에서 2018년에 훨씬 더 높은 품질의 컬러 포토리얼리스틱한 얼굴로 어떻게 발전했는지 볼 수 있습니다. 그들은 실제로 오늘날까지 더 나아지고 있습니다.\n",
    "\n",
    "<img src=\"./images/C1W1.05.png\" width=\"700\">\n",
    "<br>\n",
    "예를 들어, 2020년 초 이래로 고해상도의 전문 사진처럼 보이는 이와 같은 이미지를 생성할 수 있는 사실적인 비디오 GAN의 발전이 증가했습니다. 그들은 부드러운 배경 효과와 모든 것을 가지고 있습니다. 이 사람들이 실존한다고 생각하기 쉽지만 실제로는 존재하지 않습니다. 놀랍지 않나요?\n",
    "\n",
    "<img src=\"./images/C1W1.06.png\" width=\"700\">\n",
    "<br>\n",
    "GAN은 주어진 훈련 데이터로부터 배울 수 있습니다. 그들은 사람의 얼굴을 재현하는 것에 국한되지 않습니다. 다음은 이전 모델과 동일하지만 이번에는 고양이를 생성하는 모델입니다. 이 경우 생성된 모든 예제가 완벽하지 않기 때문에 자세히 보면 정말 이상하게 보이는 이미지를 볼 수 있습니다. \n",
    "<img src=\"./images/C1W1.07.png\" width=\"700\">\n",
    "<br>\n",
    " \n",
    "여기에서 어떤 고양이가 일어나고 있는 것처럼 보이지만 물론 그것이 무엇인지 전혀 모릅니다.\n",
    "<img src=\"./images/C1W1.08.png\" width=\"700\">\n",
    "<br>\n",
    "또한 꽤 멋진 점은 텍스트가 있는 이미지를 실제로 관찰할 수 있다는 것입니다. 이것은 앞서 언급했듯이 생성 모델이 훈련에 사용하는 데이터의 분포를 모방하려고 하기 때문에 발생합니다. \n",
    "\n",
    "<img src=\"./images/C1W1.09.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "이 경우에는 이러한 모든 고양이의 웹에서 스크랩한 훈련 데이터가 포함되며 여기에는 많은 밈 텍스트가 있는 밈도 포함됩니다. 물론 재미있는 점은 생성 모델이 단어를 모델링하려는 것이 아니라 시각적 사실적 효과이기 때문에 생성된 고양이 밈의 이러한 밈 텍스트가 실제로 단어를 구성하지 않는다는 것입니다.\n",
    "<img src=\"./images/C1W1.10.png\" width=\"700\">\n",
    "<br>\n",
    "즉, 이들 중 일부는 아직 Reddit에 대한 준비가 되지 않았을지라도 실제로 꽤 귀엽고 현실적입니다.\n",
    "\n",
    "<img src=\"./images/C1W1.11.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "\n",
    "### GANs for Image translation (이미지 변환)\n",
    "GAN은 또한 이미지 변환을 수행할 수 있습니다. 즉, 한 도메인에서 이미지를 가져와 다른 도메인으로 변환할 수 있습니다. 예를 들어 말의 이미지를 얼룩말로 또는 그 반대로 변환할 수 있습니다. 정말 흥미로운 점은 얼룩말과 말이 같은 행동을 하는 예가 실제로 필요하지 않고, 그 스타일을 그대로 옮기는 것입니다.\n",
    "\n",
    "<img src=\"./images/C1W1.12.png\" width=\"700\">\n",
    "<br>\n",
    "같은 방식으로 GAN은 그림을 그리는 데 도움이 될 수 있습니다. 이 모델은 풍경을 대략적으로 그려서 사실적으로 만들 수 있습니다. 따라서 여기 왼쪽에 브러시 스트로크를 사용할 수 있습니다. 이것은 구름이나 산, 호수와 같이 서로 다른 클래스의 정말 거친 붓놀림을 한데 모은 것입니다. 그러면 이 대략적인 스케치에서 GAN이 정말 사실적인 것을 생성할 수 있습니다. 이 GIF에서 사람은 몇 개의 선과 색상으로 대략적인 스케치를 만들 수 있으며, GAN은 이를 사실적인 그림으로 변환할 수 있습니다.\n",
    "\n",
    "<img src=\"./images/C1W1.13.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "### GANs are Magic !\n",
    "GAN은 또한 모나리자와 같은 정물 초상화를 촬영하고 실제 사람의 얼굴 모션을 사용하여 애니메이션을 적용할 수도 있습니다. 그들은 역할을 하기 위해 모나리자처럼 보일 필요조차 없습니다. Hogwarts에서 말하는 초상화를 상기한다면, 당신은 혼자가 아닙니다. 어떤 의미에서 GAN은 마술입니다.\n",
    "\n",
    "<img src=\"./images/C1W1.14.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "### GANs for 3D Objects\n",
    "GAN은 2D 이미지에 그치지 않고 의자 및 테이블과 같은 3D 개체도 생성할 수 있습니다. 이것은 집에 멋진 가구를 만들 수 있는 생성적 디자인과 같은 분야에 적용할 수 있습니다. 또한 GAN을 사용하여 인공 의료 데이터를 생성하거나 X선의 이상을 감지할 수 있는 의학 분야의 다양한 응용 프로그램이 있습니다. 이 과정에서 이에 대한 자세한 내용을 볼 수 있지만 멋진 응용 프로그램을 모두 표시하는 데 몇 시간이 걸릴 수 있습니다. \n",
    "\n",
    "<img src=\"./images/C1W1.15.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "### Companies using GANs\n",
    "몇몇 저명한 회사들도 다양한 애플리케이션에 생성적 적대 네트워크를 사용하기 시작했습니다. 예를 들어, Adobe는 초보자 아티스트가 전문가 수준의 작업을 수행할 수 있는 차세대 Photoshop에 대해 생각하고 있습니다. Google은 주로 텍스트 생성에 사용하지만 이미지에도 사용합니다. IBM은 데이터 보강을 위해 GAN을 사용하고 있으므로 GAN을 사용하여 예를 들어 특정 클래스 또는 특정 유형의 이미지에 대한 데이터가 충분하지 않은 경우 분류기 다운스트림에 대한 데이터 세트를 보강하는 합성 예제를 생성합니다. Snapchat과 TikTok은 여러분이 아마 보고 사용했을 독창적인 새 필터에서 작동하도록 했습니다. 디즈니도 초고해상도를 위해 그것들을 사용하고 있습니다. 전문화 과정이 끝나면 원하는 애플리케이션에 GAN도 사용할 수 있습니다.\n",
    "\n",
    "<img src=\"./images/C1W1.16.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "### 요약\n",
    "\n",
    "요약하면, 지난 몇 년 동안 GAN이 달성한 발전을 마무리합니다. 몇 가지 정말 멋진 응용 프로그램을 보여 줬고 일부 주요 회사에서 GAN을 사용하는 방식에 대해 언급했습니다. GAN과 관련하여 할 일이 더 많고 이러한 모델을 사용하기 위해 취할 수 있는 많은 잠재적인 방향이 있습니다.\n",
    "\n",
    "* GAN의 성능이 빠르게 향상되고 있습니다.\n",
    "* 이 분야에서 일할 수 있는 엄청난 기회\n",
    "* 주요 기업에서 사용 중"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-skirt",
   "metadata": {},
   "source": [
    "## Intuition Behind GANs\n",
    "GAN은 사람의 얼굴과 같이 기존의 실제 물체와 구별하기 어려운 사실적인 물체를 생성하는 방법을 배우는 강력한 모델입니다. GAN은 Generator와 Discriminator를 서로 경쟁하게 하여 학습합니다. 이번 영상에서는 Generator와 Discriminator의 목표에 대해 이야기해 보도록 하겠습니다. 그리고 우리가 정말 훌륭하고 원하는 사실적인 이미지를 생성할 수 있는 생성기를 얻을 때까지 서로를 위해서 실제로 어떻게 작동하는지 알 수 있습니다.\n",
    "\n",
    "* 생성자와 판별자의 목적\n",
    "* 그들 간의 경쟁\n",
    "<br>\n",
    "\n",
    "따라서 GAN에는 두 가지 구성 요소가 있습니다. 하나는 생성자라고 하고 다른 하나는 판별자라고 합니다. 그리고 이들은 일반적으로 두 개의 다른 신경망입니다. 생성자는 판별자를 속이기 위해 실제처럼 보이는 가짜를 생성하는 방법을 배웁니다. 그리고 판별자는 진짜와 가짜를 구별하는 법을 배웁니다. 따라서 생성자는 그림 위조자로, 판별자는 아트 인스펙터로 생각할 수 있습니다.\n",
    "<img src=\"./images/C1W1.17.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "따라서 생성자는 가능한 한 사실적으로 보이도록 가짜 이미지를 위조하고 판별자를 속일 수 있기를 희망하며 이 작업을 수행합니다. 여기서 Starry Night와 Scream을 볼 수 있습니다. 꽤 좋아 보입니다.\n",
    "<img src=\"./images/C1W1.18.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "한편 여기의 판별자는 실제 유명 그림과 생성자가 만든 가짜 그림의 더미를 찾습니다. 그리고 어떤 것이 진짜이고 어떤 것이 가짜인지 구별하려고 노력합니다.\n",
    "<img src=\"./images/C1W1.19.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "그래서 여기 그 분홍 자줏빛 테두리가 있는 것은 가짜이고 녹색으로 테두리가 있는 것은 진짜입니다.\n",
    "<img src=\"./images/C1M1.20.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "그리고 이 설정에서 약간 알 수 있듯이, 판별자를 속이기 위해 생성자는 실제 그림과 더 비슷하게 보이는 그림을 위조하려고 합니다. 그리고 생성자를 잡기 위해 판별자는 가장 가까운 복제본에도 속지 않는 방법을 배우려고 합니다. 따라서 이 게임을 시작하려면 유명한 그림과 같은 진짜 이미지 모음만 있으면 됩니다. 생성자가 유명한 그림을 그리도록 하려면. 그래서 이 게임의 시작 부분에서 생성자는 실제로 그다지 정교하지 않습니다. 실제처럼 보이는 예술 작품을 만드는 방법을 모르기 때문에 나는 그림을 그리려고 하는 개의 밈으로 생성자를 나타내려고 합니다.\n",
    "<img src=\"./images/C1M1.21.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "또한 생성자는 실제 이미지를 볼 수 없습니다. 이 그림이 어떻게 보일지조차 모릅니다. 그래서 이것은 생성자에게, 특히 처음에는 정말 정말 어렵습니다. 그래서 처음에 기본 생성자는 처음에 낙서의 걸작을 칠합니다. 그리고 그녀를 판단하지 마십시오. 아무도 그녀에게 무엇을 하고 무엇을 생성해야 하는지 알려주지 않았습니다.\n",
    "<img src=\"./images/C1M1.22.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "따라서 다른 시작 구성 요소는 실제로 무엇이 진짜이고 무엇이 가짜인지 확실히 알지 못하는 기본 판별자입니다. 그리고 여기에서는 베레모를 쓴 개로 표현되어 여기에서 예술 평론가가 되려고 합니다. 그러나 이 경우에는 실제 작품을 볼 수 있습니다. 그것은 가짜 것들과도 뒤죽박죽이 되어 있고 어느 것이 어느 것인지 모릅니다. 그것은 그가 알아내고 결정하는 방법을 배우기 위한 것입니다.\n",
    "<img src=\"./images/C1M1.23.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "따라서 경쟁을 시작하려면 실제 아트워크를 사용하여 판별자를 훈련하여 실제로 어떤 이미지가 실제인지 알 수 있도록 합니다. 그래서 결정한 후에는 이것이 진짜처럼 보일 수 있습니다. 실제로 예, 그것이 진짜인지 아니오, 그것은 가짜라고 말할 수 있습니다. 이렇게 하면 이와 같이 잘못 그려진 이미지를 약간 더 나은 이미지와 결국 실제 이미지와 구별할 수 있는 판별자를 얻을 수 있습니다. 물론 판별자는 이것들을 모두 뒤죽박죽으로 만들어서 어떤 것이 진짜이고 어떤 것이 가짜인지 미리 알지 못합니다. 그러나 당신은 그것이 어떤 것이 진짜이고 어떤 것이 가짜인지 배우면서 그 두 부류를 결정하는 것이 옳고 그른지 알 수 있습니다.\n",
    "<img src=\"./images/C1M1.24.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "그리고 생성자가 일련의 그림을 생성할 때 생성자는 판별자가 그녀의 작업에 할당한 점수를 보고 어떤 방향으로 진행하고 개선할지 알 것입니다. 그래서 이것은 조금 더 사실적으로 보이므로 여기 생성자가 조금 더 사실적으로 그림을 그리기 시작할 것입니다. 아마도 모나리자의 얼굴을 향해서, 아직 거기까지는 아니지만 거의.\n",
    "<img src=\"./images/C1M1.25.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "그리고 판별자는 시간이 지남에 따라 생성자로부터 각 라운드마다 점점 더 사실적인 이미지를 수신하기 때문에 개선됩니다. 그리고 항상 기억하고 진짜 이미지와 가짜 이미지를 모두 수신합니다. 모두 더미로 뒤섞여 있습니다. 그러나 본질적으로 이러한 이미지가 좋아질수록 더 예리하고 예리한 눈을 개발하려고 합니다. 그리고 여기 생성자에 의해 생성된 이 이미지가 60% 실제라고 말할 때. 당신은 그것이 60% 진짜라고 말한 후에 실제로 그것이 반드시 진짜가 아니며 실제로 가짜라고 말하는 것은 잘못된 것이라고 말합니다.\n",
    "<img src=\"./images/C1M1.26.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "그리고 나서 생성자는 많은 라운드 후에 구별하기 더 어렵고 더 어려운 그림을 생성하기 시작할 것입니다. 판별자가 진짜와 구별하는 것이 불가능하지 않다면. 그리고 이 시점에서 좋은 생성자를 원하는 사람은 멋진 가짜 이미지를 생성합니다. 이 생성자의 결과에 만족하면 게임이 종료됩니다.    \n",
    "<img src=\"./images/C1M1.27.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "### 요약\n",
    "따라서 이 강의에서 요약하자면 생성자의 목표는 판별자에게 진짜처럼 보이는 가짜를 생성하는 것이라는 점을 알고 가는 것이 중요합니다. 판별자의 목표는 생성자의 가짜와 사용자가 제공하는 실제 예제를 구별하는 것입니다. 따라서 두 모델은 생성자가 생성한 예제가 판별자를 속일 만큼 충분히 좋을 때까지 서로의 경쟁을 통해 학습합니다. 다음 비디오에서는 이 직관을 사용하여 이 경쟁이 어떻게 작동하는지 더 깊이 파고들 것입니다.\n",
    "\n",
    "* 생성자의 목표는 감별자를 속이는 것이다.\n",
    "* 감별자의 목표는 진짜와 가짜를 구별하는 것이다. \n",
    "* 그들은 서로 와의 경쟁을 통해서 학습한다.\n",
    "* 마지막에는 가짜가 진짜처럼 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-enclosure",
   "metadata": {},
   "source": [
    "## 판별자(Discriminator)\n",
    "GAN은 판별기와 생성기의 두 가지 모델로 구성됩니다. 이 비디오에서는 먼저 판별기가 어떻게 작동하는지 보여 드리겠습니다. 판별기는 일종의 분류기이므로, 그것이 무엇인지에 대한 복습으로 시작하겠습니다. 그런 다음 분류기가 학습하는 것을 확률론적 용어로 살펴보고, 이 색션의 끝에서 이 모든 것이 GAN의 판별기로 변환되는 방법을 보여 드리겠습니다.\n",
    "\n",
    "* 분류기 복습\n",
    "* 확률로 본 분류기의 역할\n",
    "* 판별기\n",
    "\n",
    "#### 분류기(Classifier)\n",
    "요약하자면 분류기의 목표는 서로 다른 클래스를 구별하는 것입니다. 따라서 이 고양이 이미지가 주어지면 분류기는 예를 들어 고양이와 개를 구별할 수 있어야 합니다. 사실, 고양이를 여러 다른 클래스에서 구별하는 방법을 배울 수 있으며, 이는 구별하려는 클래스에 따라 다릅니다. 아마도 가장 간단한 경우는 아마도 고양이가 아닌 것과 고양이일 것입니다.\n",
    "<img src=\"./images/C1M1.28.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "분류기는 이미지 클래스를 결정하는 데 국한되지 않으므로, 이 텍스트 조각을 바로 여기에 가질 수 있습니다. \"It meows, and plays with yarn\". 또는, 고양이가 부르르 거리는 비디오나, 모든 종류의 것이 분류의 대상일 수 있습니다.\n",
    "<img src=\"./images/C1M1.29.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "#### 신경망(Neural Networks)\n",
    "분류기에 대한 한 가지 유형의 모델은 신경망을 사용하는 것이고, 이 신경망은 일부 특징 $X$를 취할 수 있습니다. 예를 들어 여기에 $X_0, X_1, X_2$가 있고 $X_n$까지 있으므로 $n$개의 서로 다른 특징이 있습니다. 그것은 일련의 비선형성을 계산하는데, 나중에 다루게 될 것이고, 범주 세트에 대한 확률을 출력할 것입니다. 그리고 이 이미지가 고양이일 가능성이 45%, 개일 가능성이 45%, 이 이미지가 새일 가능성이 10%라고 생각합니다. 그리고 처음에는 모델이 올바르게 분류하는 방법을 모를 것이므로 고양이와 개가 여기에서 아마 동등할 것입니다. 그리고 데이터의 실제 레이블에 따라 예측을 개선하기 위해 오래동안 학습합니다. 그래서 당신은 마지막에 말할 것입니다, 아니요. 이것은 100% 고양이, 0% 개, 0% 새입니다.\n",
    "<img src=\"./images/C1M1.30.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "#### 분류기(훈련)\n",
    "따라서 이 학습과정은 다음과 같이 요약될 수 있다. 당신은 purrs와 털실을 가지고 노는 것을 좋아하는 것 같은 몇 가지 입력 특징 $X$를 가지고 있고, 각 클래스와 관련된 레이블 세트 $Y$를 가지고 있습니다. 예를 들어 고양이, 개, 새. 그리고 신경망을 사용합니다. 신경망은 이러한 특징을 받아들이고 제가 $\\theta$ 라고 부를 매개변수 세트를 학습합니다. 그리고 이것들은 신경망에서 볼 수 있는 각각의 노드입니다. 그리고 이 가중치는 고양이가 어떻게 생겼는지, 개가 어떻게 생겼는지, 새가 어떻게 생겼는지 배우면서 시간이 지남에 따라 바뀝니다. 그리고 이 매개변수 $\\theta$ 는 이러한 특징 $X$를 해당 레이블 $Y$에 매핑하려고 합니다. 그리고 이러한 예측은 정확히 $Y$ 레이블이 아니기 때문에 $\\hat{Y}$ 라고 부를 것입니다. 그들은 $Y$ 레이블이 되려고 합니다. 따라서 목표는 예측 $\\hat{Y}$에서 실제 값 $Y$ 간의 차이가 최소화되는 지점에 도달하는 것입니다. 그리고 이것은 비용 함수가 들어오는 곳이며, $\\hat{Y}$가 $Y$에 얼마나 근접한지를 비교하여 계산됩니다. 그리고 이것이  이 비용 함수의 목표이며, 이 신경망의 이 판별 모델이 얼마나 가깝게 고양이를 올바르게 분류하고, 개를 올바르게 분류하고, 새를 올바르게 분류하는 지를 알려주게 됩니다. 따라서 이 비용 함수에서 해당 매개변수를 업데이트할 수 있습니다. 이 비용 함수의 기울기에 따른 신경망의 노드. 그리고 그것은 일반적으로 올바른 답에 도달하기 위해  해당 매개변수가 어떤 방향으로 가야 하는지를 의미합니다. $\\hat{Y}$가 가능한 한 $Y$에 가깝에 도달하기 위해서 입니다. 그런 다음 분류기가 좋은 상태가 될 때까지 이 과정을 반복합니다. \n",
    "<img src=\"./images/C1M1.31.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "판별기의 목표가 각 클래스의 확률을 모델링하는 것인 수학의 세계로 잠시 들어가 보겠습니다. 예를 들어 여기 고양이뿐만 아니라 거북이, 새, 개, 물고기도 있습니다. 예를 들어, 입력 특징 세트가 주어지면, 즉, 이 고양이 이미지가 주어지면, 이것은 어떤 클래스입니까? 즉, 입력 특징 $X$가 주어지면 클래스 $Y$일 확률을 모델링하는 것입니다.\n",
    "<img src=\"./images/C1M1.32.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "그리고 다시 말하지만, 이러한 특징은 이 이미지에서 추출된 특징일 수 있습니다. 예를 들어 갸르릉거리고 털실을 가지고 노는 것을 좋아하지만 픽셀 자체도 마찬가지입니다. 그리고 이것은 **조건부 확률 분포**입니다. 왜냐하면 이것은 **특정 특징 세트에 따라 조건이 지정된 클래스 Y의 확률을 예측**하기 때문입니다. 이것이 이 수직 막대의 용도입니다. 따라서 모델은 입력 특징을 본 후에만 클래스를 예측합니다. 이 경우 이미지에 있습니다.\n",
    "<img src=\"./images/C1M1.33.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "이제 GAN 컨텍스트로 다시 가져옵니다. 판별기는 예제를 검사하는 분류기입니다. 그것들은 가짜 예제, 진짜 예제이며, 진짜 또는 가짜 클래스에 속하는지 여부를 결정합니다. 그래서 여기 이 가짜 모나리자를 가지고 이 이미지에 고양이, 개 또는 새가 있는지 확인하는 대신, 이 이미지가 얼마나 가짜인지 확인하고 여기에서 85%가 가짜라고 생각합니다. 확률적 측면에서 판별기는 입력 세트 X가 주어지면 예제가 가짜일 확률을 모델링합니다. 예를 들어, 이 가짜 모나리자 사진을 보고 85% 확률로 실제가 아니라고 결정합니다. 그리고 단순화하면 가짜로 분류됩니다. 그리고 이것을 0.15 진짜로 생각하고 주어진 이미지가 주어진 진짜에 대한 확률로 이것을 다시 작성할 수도 있습니다. \n",
    "<img src=\"./images/C1M1.34.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "판별기는 입력 집합 $X$가 주어지면 예제가 가짜일 확률을 모델링합니다. 예를 들어, 모나리자 또는 가짜 모나리자의 사진을 보고 85% 확률로 이것이 진짜가 아니라고 결정합니다. 0.85 가짜.\n",
    "따라서 이 경우 해당 정보는 가짜로 분류됩니다. 그리고 이 가짜 정보뿐만 아니라 이 0.85는 생성기의 노력을 개선하기 위해 제공될 것입니다.\n",
    "<img src=\"./images/C1M1.35.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "### 요약\n",
    "요약하면, 판별기는 이미지의 RGB 픽셀 값과 같은 입력 특징 집합이 주어지면 예제가 진짜 또는 가짜일 확률을 모델링하는 방법을 배우는 분류기 유형입니다. 판별기의 출력 확률은 생성기가 시간이 지남에 따라 더 보기 좋은 예제를 생성하는 방법을 배우는 데 도움이 되는 확률입니다.\n",
    "\n",
    "* **판별자**는 분류기이다.\n",
    "* 주어진 특징 $X$ 에 대하여, 클래스 $Y$ (**진짜 또는 가짜**)의 확률을 학습한다. \n",
    "* 확률은 $생성자$에 대한 피드백이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-korean",
   "metadata": {},
   "source": [
    "### 생성자(Generator)\n",
    "생성자는 심장과 같습니다. 이는 예제를 생성하는 데 사용되는 모델이며, 훈련 과정이 끝날 때 매우 높은 성능을 달성하는데 도움이 되도록 투자해야 합니다. 이 비디오에서는 생성기의 역할을 다시 살펴보고 어떻게 성능을 향상시킬 수 있는지 알게 될 것입니다. 그런 다음 확률 측면에서 모델이 무엇인지 보여 드리겠습니다.\n",
    "\n",
    "* 생성자가 하는 일\n",
    "* 그 성능을 어떻게 개선하는가?\n",
    "* 확률 측면에서의 생성자\n",
    "\n",
    "#### 생성자\n",
    "생성기의 최종 목표는 특정 클래스에서 예제를 생성할 수 있도록 하는 것입니다. 따라서 고양이 클래스에서 훈련한 경우 생성기는 일부 계산을 수행하고 실제처럼 보이는 고양이 표현을 출력합니다.\n",
    "<br>\n",
    "<img src=\"./images/C1M1.36.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "#### 신경망\n",
    "이상적으로는 생성기가 실행될 때마다 동일한 고양이를 출력하지 않고 매번 다른 예제를 생성할 수 있도록, 실제로 **노이즈 벡터**라고도 하는 **서로 다른 임의 값 세트를 입력**하게 됩니다. 여기에서 이 노이즈 벡터는 실제로 서로 다르게 음영 처리된 셀이 다른 값인 값 집합입니다. 따라서 이것을 $[1, 2, 5, 1.5, 5, 5, 2]$로 생각할 수 있습니다. 그런 다음 이 노이즈 벡터가 입력으로 제공되며 때로는 cat에 대한 클래스 y와 함께 생성기 신경망에 입력됩니다. 즉, $x_0, x_1, x_2, x_n$까지의 이러한 특징에는 이 노이즈 벡터의 숫자뿐만 아니라 클래스도 포함됩니다. 따라서 이 신경망의 생성기는 해당 입력에서 일련의 비선형성을 계산하고, 귀여운 갈색 및 흰색 고양이로 보이는 일부 변수를 반환합니다. 따라서 여기에서는 다른 클래스 대신에 **실제로 이미지가 출력**됩니다. 따라서 이 이미지에 300만 픽셀이 있다고 상상할 수 있습니다. 그래서 끝에 300만 노드가 있다고 상상할 수 있습니다. 이 노드는 클래스가 아니라 각 픽셀의 값을 나타내게 됩니다.\n",
    "<img src=\"./images/C1M1.37.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "다른 실행에서는 이 스핑크스 고양이를 생성할 수 있습니다.\n",
    "<img src=\"./images/C1M1.38.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "또 다른 실행에서는 이 사바나 고양이일 수 있습니다. 이것들은 모두 다른 노이즈 벡터를 가지고 있습니다.\n",
    "<img src=\"./images/C1M1.39.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "#### 신경망 : 학습\n",
    "자 이제는 **생성기가 시간이 지남에 따라 어떻게 개선되는지** 개념적으로 살펴보겠습니다. 먼저, **노이즈 벡터 또는 임의의 입력 값**이 있습니다. 여기 그리스 기호 $\\xi$로 나타낼 것입니다. 이것을 신경망으로 표시되는 **생성기에 전달**하여 고양이의 이미지나 고양이에 대한 시도를 나타낼 수 있는 **일련의 특징을 생성**합니다. 예를 들어 생성기가 이것을 생성할 수 있습니다. 이 **이미지 $\\hat{X}$은 판별기에 입력**되어 검사를 기반으로 얼마나 진짜인지 가짜인지 판별합니다. 그 후, **판별기가 생각하는 것**, 여기에서 $d$가 판별기 예측임을 나타내는 이 $\\hat{Y}_d$에서 기본적으로 생성기에 의해 **생성된 예제가 실제로 간주되는 정도를 확인하는 비용 함수를 계산**할 수 있습니다. 생성기가 이것이 가능한 한 실제처럼 보이기를 원하기 때문에 . 따라서 기본적으로 **생성기는 $\\hat{Y}_d$이 가능한 한 판별기에 의해서 진짜를 의미하는 1에 가깝기를 원합니다**. 반면, 판별기는 이것을 $0$, 가짜로 판단하려고 합니다. 그는 **이 둘의 차이를 사용하여 생성기의 매개변수를 업데이트**합니다. 그러면 시간이 지남에 따라 개선되고 매개변수를 이동하는 방향을 파악하여 더 실제처럼 보이고 판별기를 속일 수 있는 것을 생성합니다.\n",
    "<img src=\"./images/C1M1.40.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "따라서 꽤 좋아 보이는 생성기를 얻게되면, 생성기의 매개변수 $\\theta$ 를 저장할 수 있습니다. 이는 일반적으로 해당 세타 값을 동결하고, 어딘가에 저장한 다음 다시 로드한 다음 이 안전한 생성기에서 샘플링할 수 있음을 의미합니다. 샘플링이 기본적으로 의미하는 것은 이러한 임의의 노이즈 벡터가 있다는 것이며, 이를 저장된 생성기에 입력하면 모든 종류의 다른 예를 생성할 수 있습니다. 그래서 이 저장된 생성기는 개를 생성하기 때문에 고양이에 대해 훈련되지 않았습니다. 이제 계속해서 새로운 노이즈 벡터를 생성하고 이 저장된 생성기를 통해 넣은 다음 이 경우 더 많은 개 이미지를 샘플링할 수 있습니다.\n",
    "<img src=\"./images/C1M1.41.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "따라서 확률분야에서 생성기는 고양이와 같은 예의 확률을 모델링합니다. 앞의 예에서는 실제로 개였습니다. 물론 거북이, 새 또는 물고기 중 하나를 할 수 있습니다.\n",
    "<img src=\"./images/C1M1.42.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "더 일반적으로, **생성기는** 고양이의 이 클래스 $Y$를 감안할 때 발이 핥거나, 귀여운 수염이 있는 것과 같은 **고양이의 이러한 특징들의 확률을 모델링**하려고 합니다. 따라서 이것은 **클래스 $Y$가 주어진 특징 $X$의 조건부 확률**입니다. 그러나 현재 고양이를 생성한다고 가정해 보겠습니다. 클래스가 하나뿐이므로 $Y$는 항상 동일하므로 여기에서 실제로 필요하지 않습니다. 모델링하고 있는 $X$의 $P$가 있다는 것입니다. 물론 생성기가 모든 다른 유형의 클래스에서 학습하도록 하고 해당 클래스에 관심이 있다면 해당 클래스를 입력해야 합니다. 이에 대한 자세한 내용은 코스 1을 통해 곧 볼 수 있습니다.\n",
    "<img src=\"./images/C1M1.43.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "이제 여러분은 전 세계의 다양한 고양이 유형에 대해 $P(X)$를 갖게 되었습니다. 생성기는 추가 조건 없이 특징 $X$의 확률을 모델링합니다. 이는 클래스 $Y$가 항상 고양이이기 때문에 모든 확률 $X$에 대해 암시적이기 때문입니다. 이 경우 고양이의 실제 분포를 근사화하려고 시도합니다. 따라서 가장 일반적인 고양이 품종은 데이터 세트에서 더 일반적이기 때문에 실제로 생성될 가능성이 더 많습니다. 뾰족한 귀와 같은 특정 기능은 대부분의 고양이가 있기 때문에 추가 설명이 될 것입니다. 그러나 더 희귀한 품종은 표본이 될 가능성이 낮아집니다. 그래서 여기 있는 이 선들은 고양이 종류가 어떻게 분포되어 있는지에 대한 3D 확률 분포를 나타냅니다. 따라서 고양이가 가지는 가장 일반적인 유형의 특징은 여기 이 중간에 표시되고 샘플링됩니다. 이것을 3D 표현으로 생각하면 바깥으로 나오는 것으로 나타납니다. 그러면 희귀 품종이나 희귀해 보이는 모자가 가장자리에 있을 것입니다. 따라서 이것은 가장 일반적인 고양이 종자가 생성될 기회가 더 많고, 스핑크스와 같은 덜 일반적인 고양이 종자는 훨씬 더 드물게 생성된다는 것을 의미합니다. 향후 비디오에서 샘플링 프로세스를 제어하고 원하는 것을 얻는 방법을 볼 수 있지만, 지금의 생성기는 고양이가 자연 세계에서 어떻게 존재하는지 모델링하는 것입니다.\n",
    "<img src=\"./images/C1M1.44.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "#### 요약\n",
    "결론적으로 생성기는 진짜처럼 보이려고 하는 가짜 데이터를 생성합니다. 데이터 클래스에서 특성 $X$의 분포를 모방하는 방법을 배웁니다. 매번 다른 출력을 생성하기 위해 임의의 특징을 입력으로 사용합니다. 이번 주 과제에서는 숫자 이미지를 생성하는 GAN을 만들 것입니다. 그것은 동일한 설정을 가지고 있습니다. 무작위 노이즈를 주면 이 5와 8과 같이 손으로 쓴 모든 다른 숫자를 생성할 수 있습니다. 필기가 완벽해 보이지 않고 매번 동일하게 보이지 않으며 다양한 5와 8의 범위와 이 손으로 쓴 숫자 데이터 세트에서 모든 종류의 다른 숫자를 모델링하고 생성할 수 있기 때문에 이것은 멋진 일입니다. 과제에서 볼 수 있습니다.\n",
    "\n",
    "* 생성자는 가짜 자료를 생성한다.\n",
    "* 이것은 특징들 $X$ 의  확률을 학습한다.\n",
    "* 생성자는 잡음(무작위 특징들)을 입력으로 취한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-vinyl",
   "metadata": {},
   "source": [
    "### BCE 비용 함수\n",
    "이진 교차 엔트로피 함수(Binary Cross Entropy function) 또는 줄여서 BCE는 GAN 훈련에 사용됩니다. 진짜와 가짜와 같은 두 가지 범주가 있는 분류 작업을 위해 특별히 설계되었기 때문에 이러한 모델에 유용합니다. 이 비디오에서는 BCE 손실을 얻는 데 사용되는 방정식과 방정식의 모든 부분이 의미하는 바를 보여 드리겠습니다. 마지막으로 BCE 비용 함수가 다른 레이블을 찾는 방법을 보여줌으로써 이 강의를 마무리하겠습니다.\n",
    "\n",
    "* Binary Cross Entropy (BCE) 손실 함수\n",
    "* 그래픽적으로 어떻게 보이는지 !\n",
    "\n",
    "#### BCE 비용 함수\n",
    "다음은 전체 BCE 비용 함수입니다. 약간 위협적으로 보일 수 있지만 이러한 각 구성 요소를 분해하고 작동 방식에 대한 직관을 제공하기 위해 예제를 제공합니다. 처음에는 여기에서 **1에서 m까지의 합계 기호와 이를 m으로 나누는 것**을 볼 수 있습니다. 이것은 기본적으로 전체 배치의 실제 예제 수인 변수 m에 대하여 합산하고 해당 예의 평균을 취하는 것을 의미합니다. 실제로는 **미니 배치의 평균 비용을 계산**합니다. 이 음수 기호가 무엇을 의미하는지 나중에 설명하겠습니다. 이 비디오 전체에서 $h$**는 모델이 만든 예측**을 나타냅니다. 여기에서 $y$**는 각기 다른 예들의 레이블**임을 알 수 있습니다. 이것들은 진짜인지 가짜인지를 나타내는 진짜 레이블입니다. 예를 들어, 진짜는 레이블 1이고, 가짜는 레이블이 0이 됩니다. $X$**는 예측을 위해 전달되는 특징**이므로 이것은 이미지가 될 수 있고 $\\theta$**는 이를 계산하는 모든 것의 매개변수**입니다. 이 경우 아마도 판별자가 될 것입니다. 판별기의 매개변수로 이러한 특징을 살펴보고 이것이 하는 것입니다. $(x, \\theta)$의 $h$입니다. 종종 이것을 $x;\\theta$의 h로 쓰기도하는 것을 볼 수 있습니다. 이는 단지 $\\theta$에 의해 매개변수화된 것을 의미합니다. 그것은 약간 더 정확하지만 지금은 그것에 대해 걱정할 필요가 없습니다.\n",
    "<img src=\"./images/C1M1.45.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "이 대괄호에서 두 개의 다른 항으로 나눌 수 있습니다. 각각을 살펴보겠습니다. 왼쪽에 있는 항은 진짜 레이블 $y$ 에 예측 로그의 곱이며, 이는 모델에 대한 $\\theta$ 로 매개변수화된 특징인 $x$의 $h$입니다. 이 값이 무엇을 얻으려고 하는지 이해하기 위해 몇 가지 예를 살펴보겠습니다. 레이블이 0인 경우, 이것이 가짜임을 의미하고, 여기에 예측이 있으면 이 값은 실제로 0이 됩니다. 예측이 1인 경우 그것은 진짜이고 예측이 매우 높다고 가정해 보겠습니다. 0.99 로 1에 가까우면 0에 가까운 값을 다시 얻게 됩니다. 실제로는 진짜이지만 예측이 끔찍하고 0인 경우 1에서 멀리 떨어져 있으면 가짜라고 생각하지만 실제로 진짜라면 이 값은 매우 큽니다. 이것은 주로 로그에 의해 발생합니다. 이것이 말하려는 것은 \n",
    "실제 예측이 0인 경우 이 항은 중요하지 않고 0으로 간다는 것입니다. 이 항은 주로 예측이 실제로 1일 때를 위한 것이며, 예측이 좋으면 이 항이 0이 됩니다.  예측이 좋지 않으면 음의 무한대가 됩니다.\n",
    "    \n",
    "<img src=\"./images/C1M1.46.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "이제 두 번째 항을 보면 매우 유사해 보입니다. 이 빼기 기호 중 일부를 여기에 저장합니다. 이 경우 레이블이 1이면 1 빼기 $y$는 0과 같아집니다. 실제로 예측이 무엇이든 이 항은 0으로 평가됩니다.\n",
    "그리고, 예측이 '이봐, 아주 가짜다, 0에 가까워진다'고 말하면 이 값은 0에 가까워집니다. 그러나 그것이 가짜이지만 예측은 그것이 진짜라고 생각한다면, 이 항은 음의 무한대로 평가됩니다. 기본적으로 이러한 **각 항들은 관련 레이블에 대한 예측이 정말 나쁜 경우 음의 무한대로 평가**됩니다. 이것은 우리에게 이 부정적인 신호를 조금 가져다줍니다. 이 값 중 하나가 음의 방향으로 정말 큰 것으로 평가되는 경우 이 음수 기호는 양수와 양의 무한대인지 확인하는 데 중요합니다. **비용 함수**의 경우 일반적으로 원하는 것은 **높은 값은 나쁜 것**이고 **신경망은 이 값을 최대한 줄이려고 합니다**. 학습하면서 비용 함수를 최소화하기를 원하기 때문에 더 가까운 예측을 얻고 0으로 평가하는 것이 의미가 있습니다.\n",
    "<img src=\"./images/C1M1.47.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "요약하면 비용 함수의 **한 항은 레이블 0일 때** 관련성이 있고 **다른 항은 1일 때** 관련성이 있으며 두 경우 모두 1-0 사이의 값의 로그가 계산되어 음수 결과를 반환합니다. 그렇기 때문에 처음에 있는 이 음수 항를 사용하여 전체 비용이 높거나, 0보다 같거나 큰 지를 확인하게 해 줍니다.\n",
    "<img src=\"./images/C1M1.48.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "이제 모든 가능한 예측에 대해 각 레이블에 대한 손실 함수가 어떻게 보이는지 보여 드리겠습니다. 이 플롯에서 $x$축에 예측 값을 가질 수 있습니다. 여기서 $h$는 모델이고 $\\theta$로 매개변수화된 $x$를 기반으로 예측을 제공합니다. 해당 훈련 예제와 관련된 손실은 $y$축에 있습니다. 이 경우 손실은 예측의 음의 로그로 단순화됩니다. 예측이 1에 가까우면 여기 꼬리에서 예측이 레이블에 가깝기 때문에 손실은 0에 가깝습니다. 여기서 예측이 0에 가까울 때 불행히도 손실은 무한대에 접근하므로 예측과 레이블이 매우 다르기 때문에 매우 높은 값입니다.  \n",
    "<img src=\"./images/C1M1.49.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "레이블이 0이고 손실 함수는 1의 음수 로그에서 해당 예측을 뺀 값으로 감소하면 반대가 됩니다. 예측이 0에 가까울 때 손실도 0에 가깝습니다. 즉, 잘하고 있다는 의미입니다. 그러나 예측이 1에 가까워질 때, 실제는 0이면 다시 무한대에 접근합니다.\n",
    "<img src=\"./images/C1M1.50.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "#### 요약\n",
    "요약하면, BCE 비용 함수에는 각 클래스와 관련된 두 가지 주요 항이 있습니다. **예측과 레이블이 유사하면 BCE 손실은 0**에 가깝습니다. **매우 다를 때 해당 BCE 손실은 무한대**에 접근합니다. BCE 손실은 미니 배치(n개의 예)의 여러 예제에  걸쳐 수행됩니다. n이 5라면, 이 5개의 예 모두의 평균을 취합니다. 각각의 예는 다를 수 있습니다. 그 중 하나는 1이 될 수 있고 다른 4개는 0이 될 수 있습니다.\n",
    "\n",
    "* BCE 비용함수는 두 부분(각 해당 클래스와 연관된)으로 이루어져 있다.\n",
    "* 라벨과 예측이 유사하며 0에 가까워진다.\n",
    "* 라벨과 예측이 다르면 무한대에 접근한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-change",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "GAN 및 해당 구성 요소 뒤에 있는 직관의 모든 기본 사항을 살펴보았습니다. 이 비디오에서는 앞에서 다룬 몇 가지 개념을 검토하고, GAN 훈련을 시작할 수 있도록 모든 개념을 통합합니다. 먼저 GAN 아키텍처가 어떻게 생겼는지에 대한 표현을 공유하겠습니다. 그런 다음 판별자의 훈련과 생성자의 훈련을 번갈아 가며 GAN을 훈련하는 방법을 보여 드리겠습니다.\n",
    "\n",
    "* 전체 구조가 어떻게 생겼는지\n",
    "* GANs 을 훈련하는 방법\n",
    "\n",
    "#### GANs 모델\n",
    "기본 GAN에서 생성기는 입력으로 임의의 잡음을 취한다는 점을 기억하십시오. 이 그리스 문자 $\\xi$로 표현합니다. 그리고 이 생성기는 $\\hat{X}$ 이라는 가짜 예제를 생성합니다, 이것들은 가짜 이미지입니다. 그리고 생성기에 클래스를 전달할 필요는 없지만, 많은 다른 클래스를 생성하는 경우에는 전달할 수 있습니다. 지금은 제너레이터의 클래스를 전달하지 않을 것입니다. 이것이 어떻게 작동하는지 나중에 보여드리겠습니다. 그런 다음 생성된 예제와 실제 예제가 판별기로 전달됩니다. 판별자의 이 출력은 $\\hat{y}$이라는 확률니다. 따라서 판별자의 목표는 생성된 예제와 진짜 예제를 구별하는 것입니다. 생성기의 목표는 가능한 한 진짜처럼 보이는 가짜 예제를 생성하여 판별자를 속이는 것입니다.\n",
    "<img src=\"./images/C1M1.51.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "#### GANs 훈련 : 감별자(Discriminator)\n",
    "따라서 기본 GAN을 훈련하기 위해 생성기와 판별기에 대한 훈련을 교대로 수행합니다. 먼저 판별기가 작동하는 방식부터 시작하겠습니다. 먼저 해당 입력 노이즈에서 생성기에 의해 생성된 몇 가지 가짜 예제 $\\hat{X}$를 얻습니다. 그런 다음 이러한 예, 가짜 것, $\\hat{X}$ 및 진짜 ${X}$는 모두 판별기에게 어느 것이 진짜이고 어떤 것이 가짜인지 알려주지 않고 판별기에 전달됩니다. 그리고 나서 판별자는 어떤 것이 진짜이고 어떤 것이 가짜인지 예측합니다. 또는 보다 구체적으로 이러한 각 이미지가 얼마나 가짜이고 얼마나 실제인지에 대한 점수 확률입니다. 그런 다음 해당 BCE 손실을 사용하여 예측을 가짜 및 진짜에 대한 원하는 레이블과 비교합니다. 그리고 이는 매개변수 또는 $\\theta_d$를 업데이트하는 데 도움이 됩니다. 여기서 $d$는 판별자의 매개변수를 나타냅니다. 따라서 이것은 판별기의 매개변수만 업데이트하고 이 하나의 신경망만 업데이트하고 생성기는 업데이트하지 않습니다.\n",
    "<img src=\"./images/C1M1.52.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "#### GANs 훈련 : 생성자(Generator)\n",
    "생성기의 경우 먼저 몇 가지 가짜 예제를 생성합니다. 다시 $\\hat{X}$입니다. 이것은 입력 노이즈에서 나온 것입니다. 그리고 이것들은 다시 판별기로 전달됩니다. 그러나 이 경우 생성기는 자체 가짜 예만 봅니다. 그래서 실제 예를 전혀 보지 않습니다. 따라서 이것이 일부 판별자에게 전달되고 있다는 것만 압니다. 그리고 나서 판별자가 예측을 합니다. 이것들이 얼마나 진짜인지 가짜인지에 대한 $\\hat{Y}$을 출력합니다. 그런 다음 동일한 BCE 손실을 사용하여 예측을 모든 레이블이 진짜인 경우로 가정하여 비교합니다. 생성기는 이러한 가짜 이미지를 가능한 한 진짜 또는 레이블 1과 같게 하려고 하기 때문입니다. 이것이 생성기와 판별기 사이에 약간 까다롭고 약간 다른 부분입니다. 판별자는 가짜 예제가 가능한 한 가짜처럼 보이길 원하지만, 생성자는 가짜 예제가 가능한 한 진짜처럼 보이길 원합니다. 즉, 판별자를 속이려고 합니다. 따라서 비용을 계산한 후 그래디언트가 뒤로 전파되고 생성기 또는 매개변수 $\\theta_g$가 업데이트됩니다. 다시 말하지만, 이 과정에서 업데이트되는 것은 생성기, 이 하나의 신경망일 뿐이며 판별기가 아닙니다. 따라서 훈련을 교대로 수행하면 한 번에 하나의 모델만 훈련되고 다른 하나는 일정하게 유지됩니다.\n",
    "<img src=\"./images/C1M1.53.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "#### GANs 훈련 \n",
    "따라서 이러한 교대 방식으로 GAN을 훈련할 때 두 모델이 함께 향상되어야 하고, 훈련 초기부터 유사한 기술 수준을 유지해야 한다는 점을 염두에 두는 것이 중요합니다. 그리고 이에 대한 추론은 생성기보다 우수한 판별기가 있는 경우(예: super, super good) 모든 가짜 예제가 100% 가짜라는 예측을 얻을 수 있습니다. 글쎄, 그것은 생성기에 유용하지 않습니다. 생성기는 개선 방법을 모릅니다. 모든 것이 매우 가짜처럼 보일 뿐, 어떤 방향으로 가야 하는지 알려주는 아무 것도 없습니다. 어쩌면 조금 더 현실적이고 시간이 지남에 따라 배우는 방법을 추가하기 위한 것일 수도 있습니다. 한편, 판별기를 완전히 능가하는 우수한 생성기가 있는 경우 생성된 모든 이미지가 100% 실제라는 예측을 얻을 수 있습니다. 따라서 이러한 **교대 방식으로 GAN을 훈련할 때 두 모델이 함께 개선되어야 한다는 점**을 염두에 두는 것이 중요합니다. 그리고 **훈련 초기부터 비슷한 기술 수준을 유지**해야 합니다. 그리고 이것의 이면에 있는 추론은 주로 판별자 때문입니다. 판별자는 훨씬 더 쉬운 작업을 가지고 있습니다. 클래스가 어떻게 생겼는지 전체 공간을 모델링하는 것과는 대조적으로 어떤 것이 진짜이고 어떤 것이 가짜인지 알아내려는 것입니다. 모든 고양이의 모습입니다. 따라서 판별자의 작업은 생성자의 작업보다 훨씬 쉽습니다. 한 가지 일반적인 문제는 우수한 판별자가 있어 이 판별자가 너무 빨리 학습하도록 하는 것입니다. 그리고 너무 빨리 학습하고 갑자기 가짜 이미지를 보고 이것이 100% 가짜라고 말하면 이것이 가짜라는 것을 압니다. 하지만 이 100%는 어떻게 성장하고 배울지 모르기 때문에 제너레이터에게 전혀 유용하지 않습니다. 따라서 판별기의 출력은 100% 가짜가 아닌 0.87 가짜 또는 0.2 가짜와 같이 훨씬 더 많은 정보를 제공합니다. 하나는 가짜일 확률이 높기 때문에 가중치를 업데이트하고 시간이 지남에 따라 사실적인 이미지를 생성하는 방법을 학습한다는 점에서 생성기에 훨씬 더 많은 정보를 제공합니다.\n",
    "<img src=\"./images/C1M1.54.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "#### 요약\n",
    "따라서 여기서 가장 중요한 점은 GAN 훈련이 일반적으로 이러한 교대 방식으로 작동한다는 것입니다. 그리고 시간이 지남에 따라 그 훈련을 향상시키려면 좋은 훈련 과정을 유지하기 위해 생성자와 판별자의 척도를 서로 가깝게 유지해야 합니다. 그리고 물론, 생성기가 이미 정말 좋은 것이라면 다 된 것입니다.\n",
    "\n",
    "* GAN은 번갈아 가며 훈련합니다.\n",
    "* 두 모델은 항상 유사한 \"기술\" 수준을 유지해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-probability",
   "metadata": {},
   "source": [
    "###  Intro to Pytorch\n",
    "전문 분야의 일부 노트북은 Facebook에서 개발했으며 제가 정말 좋아하는 인기 있는 딥 러닝 프레임워크인 PyTorch를 사용했습니다. 그러나 이전에 사용하지 않았더라도 걱정하지 마십시오. TensorFlow와 같은 다른 프레임워크와 매우 유사하며 모든 노트북 할당에는 이 PyTorch 프레임워크를 사용하는 데 도움이 되는 힌트가 있습니다. 이 비디오에서는 먼저 PyTorch와 TensorFlow를 비교하겠습니다. 그런 다음 모델을 정의하는 방법과 PyTorch 함수를 사용하여 모델을 훈련하는 방법을 볼 수 있습니다.\n",
    "\n",
    "* Tensorflow 와의 비교\n",
    "* 모델 정의\n",
    "* 훈련\n",
    "\n",
    "#### PyTorch vs TensorFlow\n",
    "따라서 PyTorch와 TensorFlow는 틀림없이 현재 가장 인기 있는 딥 러닝 프레임워크입니다. 그리고 딥 러닝 전문 분야를 수강했다면 TensorFlow에 익숙할 것입니다. 그러나 여기에 비밀이 있습니다. 저는 PyTorch를 더 좋아합니다. 이들 사이의 주요 차이점은 일반적으로 계산을 수행하는 방식입니다. PyTorch에서는 이동 중에 작업을 계산하며 이를 명령형 프로그래밍이라고도 합니다. TensorFlow에서는 먼저 계산 방법을 정의한 다음 나중에 계산을 수행합니다. 이를 기호 접근 방식이라고 합니다. 따라서 이것은 PyTorch에서 A는 1, B는 2와 같이 변수 A와 B에 대한 일부 값을 가지고 있으며 이들을 합산하면 결과적으로 3이 된다는 것을 의미합니다. 글쎄요, TensorFlow에서는 A와 B에 대한 초기 값이 없지만 그 합계를 다른 변수 C에 저장할 수 있습니다. 따라서 여기에서는 약간 추상적이지만 C를 컴파일하고 그에 대한 값을 얻습니다. 계산하려면 A와 B가 있는 곳에 값을 할당해야 합니다. 따라서 이것은 PyTorch에 동적 계산 그래프를 가질 수 있는 기능을 제공하며 이는 알려진 네트워크가 실행할 때마다 구조를 매우 쉽게 변경할 수 있음을 의미합니다. 그러나 TensorFlow의 계산 그래프는 정적이기 때문에 모델을 실행하는 데 시간이 덜 걸리는 경향이 있습니다. 따라서 C = A + B 또는 이와 같은 전체 신경망을 설명하기 때문에 이러한 계산 그래프는 정적인 것으로 간주됩니다. 그리고 최근 TensorFlow 2.0에는 Eager Execution이라는 것이 있는데, 이는 동적 계산 그래프가 있는 PyTorch와 매우 유사합니다. 그러나 대체로 PyTorch에서는 동적 계산 그래프가 훨씬 더 자연스럽게 느껴집니다.\n",
    "<img src=\"./images/C1M1.55.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "그러나 전반적으로 현재 이러한 프레임워크는 매우 매우 유사하며 특히 TensorFlow에서 PyTorch 방향으로의 전환이 그 어느 때보다 쉬워졌음을 알 수 있습니다.\n",
    "<img src=\"./images/C1M1.56.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "### PyTorch 에서 모델 정의\n",
    "따라서 PyTorch에 중점을 두고 PyTorch를 사용하여 모델을 정의하는 방법부터 시작하겠습니다. 먼저 import torch 라인을 사용하여 PyTorch를 가져와야 합니다. 그리고 이것은 PyTorch 라이브러리일 뿐입니다. 그런 다음 신경망을 나타내는 nn 모듈을 가져오는 것도 유용합니다. 여기에는 딥 러닝 모델을 위한 사용자 지정 레이어가 포함됩니다. 매우 유용합니다. nn.Module 클래스의 하위 클래스를 사용하여 PyTorch에서 모델을 정의하는 것이 일반적입니다. 여기서 LogisticRegression 클래스는 로지스틱 회귀 모델을 만드는 데 도움이 됩니다. 이 클래스의 초기화 방법은 모델에 대해 원하는 매개변수를 사용하므로 이는 객체 지향 Python에서 일반적입니다. 그리고 이 경우 여기의 변수는 이 로지스틱 회귀 모델에 대한 입력 변수의 수를 결정합니다. 그런 다음 모델의 아키텍처를 생성자 초기화 내에서 속성으로 정의하고 로지스틱 회귀를 위해 Sequential 모듈이라고 하는 것 내에서 선형 레이어와 Sigmoid 활성화를 사용할 수 있습니다. 따라서 순차 모듈은 순차 계층에 계층화됩니다. 먼저 선형 레이어를 제공한 다음 시그모이드 활성화 함수를 제공합니다. 그리고 여기 선형 레이어에서 여기에서 이 변수를 전달한 것을 볼 수 있습니다. 따라서 이것은 입력의 크기이고 출력은 1입니다. 이 모든 입력에서 하나의 예측만 원합니다. 그래서 여기에서 이 1은 0과 1 사이의 값을 생성하는 시그모이드 활성화를 거치는 절단 또는 절단되지 않은 클래스일 수 있습니다. 그리고 마지막으로, 여기서 이 초기화 후에 모델 클래스의 forward 메소드를 정의하고 forward 메소드는 입력이 주어지면 모델이 출력을 생성하기 위해 정방향 패스에서 수행하는 작업을 의미합니다. 역전파가 있는 역방향 패스가 아니라 순방향 패스가 입력을 입력할 때 발생합니다. 어떻게 출력을 생성합니까? 그래서 이 경우에 여기에서 정의한 순차 모델인 self.logistic 회귀에서 입력 x가 주어지면 반환합니다. 따라서 입력 x가 주어지면 이 순차적인 레이어 집합을 통해 입력합니다. 자, 이것은 PyTtorch에서 모델을 정의하는 방법에 대한 매우 간단한 일반 개요이지만 다른 코드 구조로도 동일한 결과를 얻을 수 있습니다.\n",
    "\n",
    "```Python\n",
    "import torch\n",
    "from torch import nn                 # custom layers for DL\n",
    "\n",
    "class LogisticRegression(nn.Module): # Define the model \n",
    "                                     # as a class\n",
    "    def __init__(self, in):          # initialization method \n",
    "        super().__init__()           # with parameters\n",
    "        self.log_reg = nn.Sequential( # definition of\n",
    "            nn.Linear(in, 1),         # the architecture\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.log_reg(x)   # forward computation of \n",
    "                                 # the model with inputs x\n",
    "```\n",
    "\n",
    "### PyTorch 에서 모델 훈련\n",
    "이제 이 프레임워크에서 모델을 훈련시키려면 모델에 대해 정의한 클래스의 인스턴스를 초기화해야 합니다. 여기 LogisticRegression 클래스, 마지막 슬라이드의 이 모델에는 16개의 입력 변수가 있습니다. 그런 다음 모델에 대한 비용 함수를 결정합니다. 저는 이것을 기준이라고 부르겠습니다. 따라서 모델이 학습하는 기준입니다. 그리고 이것은 PyTorch의 비용 함수에 부여되는 일반적인 이름입니다. 그리고 여기에서는 비용 함수에 대한 BCELoss를 초기화할 것입니다. 이것은 이 nn 라이브러리인 토치 신경망 라이브러리를 통해 사용할 수 있습니다. 그 후에는 사용하려는 최적화 프로그램을 선택해야 합니다(예: 모델 매개변수를 전달하는 확률적 경사하강법). 이것은 이전에 본 세타이며 훈련 중에 업데이트될 예정입니다. 그런 다음 이 옵티마이저에 대해 다른 하이퍼 매개변수를 지정해야 합니다. 예를 들어 학습률이 여기에 있습니다. 마지막으로 다양한 epoch에 대해 모델을 훈련할 수 있으므로 n_epochs로 훈련 루프를 시작하겠습니다. 이 훈련 루프 내에서 입력을 모델에 전달하는 100이라고 가정해 보겠습니다. 모델에서 예측을 얻습니다. 그런 다음 비용 함수를 사용하여 이 기준을 사용하여 예측을 실제 출력과 비교하면 이 특정 단계에 대한 손실이 발생합니다. 그런 다음 정의한 옵티마이저를 사용하여 최적의 조치를 취하십시오. 여기에서 정확한 구문에 대해 걱정할 필요는 없지만 기본적으로 일어나는 일은 이 최적화 프로그램이 이전의 그래디언트를 0으로 만들어 모든 것이 깨끗하고 좋은지 확인하고 이것이 역전파의 중요한 단계라는 것입니다. 이것은 역전파 단계를 준비하고 여기서 마지막 옵티마이저.단계는 ​​이 작은 학습률로 모델 매개변수에 확률적 경사하강법을 사용하여 일반적인 방향으로 이동하고 해당 매개변수를 업데이트하는 것을 의미합니다.\n",
    "\n",
    "```python\n",
    "model = LogisticRegression(16)   # initialization of model\n",
    "\n",
    "criterion = nn.BCELoss()         # cost function\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for t in range(n_epochs):    # training loop for \n",
    "                             # number of epochs\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred,y)   # forward propagation\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()              # optimization step\n",
    "    optimizer.step()\n",
    "```\n",
    "\n",
    "#### 요약\n",
    "요약하자면 PyTorch는 실행 중에 계산을 수행하므로 모든 단일 실행에서 변경될 수 있는 모델을 실험할 수 있습니다. 그러나 이 비디오에서 보았듯이 PyTorch는 실제로 TensorFlow와 매우 유사한 또 다른 딥 러닝 프레임워크입니다. 이러한 프레임워크 중 하나에 이미 익숙하다면 문제 없이 이 프레임워크 간에 앞뒤로 변경할 수 있습니다.\n",
    "\n",
    "* PyTorch는 실행 중에 계산을 수행합니다.\n",
    "* PyTorch의 동적 계산 그래프\n",
    "* 또 다른 프레임워크이며, TensorFlow 와 유사하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
